diff -r ba76b741d3fe MMTk/src/org/mmtk/plan/Plan.java
--- a/MMTk/src/org/mmtk/plan/Plan.java	Wed May 20 12:33:21 2015 +0200
+++ b/MMTk/src/org/mmtk/plan/Plan.java	Fri Jun 05 16:07:58 2015 +0600
@@ -21,6 +21,7 @@
 import org.mmtk.policy.LargeObjectSpace;
 import org.mmtk.utility.alloc.LinearScan;
 import org.mmtk.utility.Conversions;
+import org.mmtk.utility.HeaderByte;
 import org.mmtk.utility.heap.HeapGrowthManager;
 import org.mmtk.utility.heap.Map;
 import org.mmtk.utility.heap.VMRequest;
@@ -29,9 +30,7 @@
 import org.mmtk.utility.sanitychecker.SanityChecker;
 import org.mmtk.utility.statistics.Timer;
 import org.mmtk.utility.statistics.Stats;
-
 import org.mmtk.vm.VM;
-
 import org.vmmagic.pragma.*;
 import org.vmmagic.unboxed.*;
 
@@ -179,6 +178,9 @@
     Options.useShortStackScans = new UseShortStackScans();
     Options.threads = new Threads();
     Options.cycleTriggerThreshold = new CycleTriggerThreshold();
+    Options.cycleTriggerFraction = new CycleTriggerFraction();
+    Options.defragTriggerFraction = new DefragTriggerFraction();
+    Options.survivorCopyMultiplier = new SurvivorCopyMultiplier();
     Map.finalizeStaticSpaceMap();
     registerSpecializedMethods();
 
@@ -392,6 +394,24 @@
     return reference;
   }
 
+  /**
+   * Perform any required initialization of the GC portion of the header.
+   * Called for objects created at boot time.
+   *
+   * @param object the Address representing the storage to be initialized
+   * @param typeRef the type reference for the instance being created
+   * @param size the number of bytes allocated by the GC system for
+   * this object.
+   * @return The new value of the status word
+   */
+  public byte setBuildTimeGCByte(Address object, ObjectReference typeRef, int size) {
+    byte status = 0;
+
+    if (HeaderByte.NEEDS_UNLOGGED_BIT)
+      status |= HeaderByte.UNLOGGED_BIT;
+    return status;
+  }
+
   /****************************************************************************
    * Allocation
    */
diff -r ba76b741d3fe MMTk/src/org/mmtk/plan/TraceLocal.java
--- a/MMTk/src/org/mmtk/plan/TraceLocal.java	Wed May 20 12:33:21 2015 +0200
+++ b/MMTk/src/org/mmtk/plan/TraceLocal.java	Fri Jun 05 16:07:58 2015 +0600
@@ -125,7 +125,7 @@
    * @param untraced <code>true</code> if <code>objLoc</code> is an untraced root.
    */
   @Inline
-  public final void processRootEdge(Address slot, boolean untraced) {
+  public void processRootEdge(Address slot, boolean untraced) {
     ObjectReference object;
     if (untraced) object = slot.loadObjectReference();
     else     object = VM.activePlan.global().loadObjectReference(slot);
diff -r ba76b741d3fe MMTk/src/org/mmtk/plan/rcimmix/RCImmix.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/plan/rcimmix/RCImmix.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,383 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.plan.rcimmix;
+
+import static org.mmtk.policy.rcimmix.RCImmixConstants.PAGES_IN_BLOCK;
+
+import org.mmtk.plan.Phase;
+import org.mmtk.plan.StopTheWorld;
+import org.mmtk.plan.Trace;
+import org.mmtk.policy.ExplicitLargeObjectSpace;
+import org.mmtk.policy.Space;
+import org.mmtk.policy.rcimmix.RCImmixSpace;
+import org.mmtk.policy.rcimmix.RCImmixObjectHeader;
+import org.mmtk.utility.Log;
+import org.mmtk.utility.alloc.LinearScan;
+import org.mmtk.utility.deque.SharedDeque;
+import org.mmtk.utility.heap.VMRequest;
+import org.mmtk.utility.options.Options;
+import org.mmtk.utility.sanitychecker.SanityChecker;
+import org.mmtk.vm.VM;
+import org.vmmagic.pragma.*;
+import org.vmmagic.unboxed.Address;
+import org.vmmagic.unboxed.ObjectReference;
+import org.vmmagic.unboxed.Word;
+
+/**
+ * This class implements the global state of RCImmix collector.
+ */
+@Uninterruptible
+public class RCImmix extends StopTheWorld {
+  public static final short PROCESS_OLDROOTBUFFER  = Phase.createSimple("old-root");
+  public static final short PROCESS_NEWROOTBUFFER  = Phase.createSimple("new-root");
+  public static final short PROCESS_MODBUFFER      = Phase.createSimple("mods");
+  public static final short PROCESS_DECBUFFER      = Phase.createSimple("decs");
+
+  /** Is cycle collection enabled? */
+  public static final boolean CC_ENABLED           = true;
+  /** Force full cycle collection at each GC? */
+  public static boolean CC_FORCE_FULL        = false;
+  /** Use backup tracing for cycle collection (currently the only option) */
+  public static final boolean CC_BACKUP_TRACE      = true;
+  public static final boolean RC_SURVIVOR_COPY = true;
+
+  public static boolean performCycleCollection;
+  public static boolean performDefrag;
+  public static int cycleTriggerThreshold;
+  public static int defragTriggerThreshold;
+  public static final short BT_CLOSURE_INIT        = Phase.createSimple("closure-bt-init");
+  public static final short BT_CLOSURE             = Phase.createSimple("closure-bt");
+
+  // CHECKSTYLE:OFF
+
+  /**
+   * Reference counting specific collection steps.
+   */
+  protected static final short refCountCollectionPhase = Phase.createComplex("release", null,
+      Phase.scheduleGlobal     (PROCESS_OLDROOTBUFFER),
+      Phase.scheduleCollector  (PROCESS_OLDROOTBUFFER),
+      Phase.scheduleGlobal     (PROCESS_NEWROOTBUFFER),
+      Phase.scheduleCollector  (PROCESS_NEWROOTBUFFER),
+      Phase.scheduleMutator    (PROCESS_MODBUFFER),
+      Phase.scheduleGlobal     (PROCESS_MODBUFFER),
+      Phase.scheduleCollector  (PROCESS_MODBUFFER),
+      Phase.scheduleMutator    (PROCESS_DECBUFFER),
+      Phase.scheduleGlobal     (PROCESS_DECBUFFER),
+      Phase.scheduleCollector  (PROCESS_DECBUFFER),
+      Phase.scheduleGlobal     (BT_CLOSURE_INIT),
+      Phase.scheduleCollector  (BT_CLOSURE_INIT), 
+      Phase.scheduleGlobal     (BT_CLOSURE),
+      Phase.scheduleCollector  (BT_CLOSURE));     
+ 
+  /**
+   * Perform the initial determination of liveness from the roots.
+   */
+  protected static final short rootClosurePhase = Phase.createComplex("initial-closure", null,
+      Phase.scheduleMutator    (PREPARE),
+      Phase.scheduleGlobal     (PREPARE),
+      Phase.scheduleCollector  (PREPARE),
+      Phase.scheduleComplex    (prepareStacks),
+      Phase.scheduleCollector  (STACK_ROOTS),
+      Phase.scheduleGlobal     (STACK_ROOTS),
+      Phase.scheduleCollector  (ROOTS),
+      Phase.scheduleGlobal     (ROOTS),
+      Phase.scheduleGlobal     (CLOSURE),
+      Phase.scheduleCollector  (CLOSURE));
+
+  /**
+   * This is the phase that is executed to perform a collection.
+   */
+  public short collection = Phase.createComplex("collection", null,
+      Phase.scheduleComplex(initPhase),
+      Phase.scheduleComplex(rootClosurePhase),
+      Phase.scheduleComplex(refCountCollectionPhase),
+      Phase.scheduleComplex(completeClosurePhase),
+      Phase.scheduleComplex(finishPhase));
+  
+  // CHECKSTYLE:ON
+
+  /*****************************************************************************
+   *
+   * Class fields
+   */
+  public static final RCImmixSpace rcSpace = new RCImmixSpace("rc", VMRequest.discontiguous());
+  public static final ExplicitLargeObjectSpace rcloSpace = new ExplicitLargeObjectSpace("rclos", VMRequest.discontiguous());
+
+  public static final int REF_COUNT = rcSpace.getDescriptor();
+  public static final int REF_COUNT_LOS = rcloSpace.getDescriptor();
+
+  public final SharedDeque modPool = new SharedDeque("mod", metaDataSpace, 1);
+  public final SharedDeque decPool = new SharedDeque("dec", metaDataSpace, 1);
+  public final SharedDeque newRootPool = new SharedDeque("newRoot", metaDataSpace, 1);
+  public final SharedDeque newRootBackPool = new SharedDeque("newRootBack", metaDataSpace, 1);
+  public final SharedDeque oldRootPool = new SharedDeque("oldRoot", metaDataSpace, 1);
+
+  /*****************************************************************************
+   *
+   * Instance fields
+   */
+  public final Trace rootTrace;
+  public final Trace backupTrace;
+  private final RCImmixBTLargeSweeper loFreeSweeper;
+  public int beginningPagesUsed = 0;
+  public static double lineSurvivalRateExp = 1.0f;
+
+  // MAX heuristic for proactive copying
+  public static final int N = 4;
+  public static double [] a = new double[N];
+
+  /**
+   * Constructor
+   */
+  public RCImmix() {
+    Options.noReferenceTypes.setDefaultValue(true);
+    Options.noFinalizer.setDefaultValue(true);
+
+    rootTrace = new Trace(metaDataSpace);
+    backupTrace = new Trace(metaDataSpace);
+    loFreeSweeper = new RCImmixBTLargeSweeper();
+  }
+
+  @Override
+  @Interruptible
+  public void processOptions() {
+    super.processOptions();
+    if (!Options.noReferenceTypes.getValue()) {
+      VM.assertions.fail("Reference Types are not supported by RC");
+    }
+    if (!Options.noFinalizer.getValue()) {
+      VM.assertions.fail("Finalizers are not supported by RC");
+    }
+    cycleTriggerThreshold = (int)(getTotalPages() * Options.cycleTriggerFraction.getValue());
+    defragTriggerThreshold = (int)(getTotalPages() * Options.defragTriggerFraction.getValue());
+  }
+
+  /*****************************************************************************
+   *
+   * Collection
+   */
+  public static final boolean isRCObject(ObjectReference object) {
+    return !object.isNull() && !Space.isInSpace(VM_SPACE, object);
+  }
+
+  @Override
+  public boolean lastCollectionFullHeap() {
+    return performCycleCollection;
+  }
+
+  @Override
+  public void collectionPhase(short phaseId) {
+    if (phaseId == SET_COLLECTION_KIND) {
+      super.collectionPhase(phaseId);
+      if (CC_ENABLED) {
+        CC_FORCE_FULL = Options.fullHeapSystemGC.getValue();
+        performCycleCollection |= (collectionAttempt > 1) || emergencyCollection || CC_FORCE_FULL;
+        RCImmixObjectHeader.performCycleCollection = performCycleCollection;
+        if (performCycleCollection && Options.verbose.getValue() > 0) Log.write(" [CC] ");
+        if (performCycleCollection) {
+          rcSpace.decideWhetherToDefrag(emergencyCollection, true, collectionAttempt, userTriggeredCollection, performDefrag);
+          RCImmixObjectHeader.performSurvivorCopy = false;
+        } else {
+          RCImmixObjectHeader.performSurvivorCopy = true;
+        }
+      }
+      rcSpace.maxCleanPagesForCopy = getCopyReserve();
+      rcSpace.exhaustedCopySpace = false;
+      return;
+    }
+
+    if (phaseId == PREPARE) {
+      super.collectionPhase(phaseId);
+      VM.finalizableProcessor.clear();
+      VM.weakReferences.clear();
+      VM.softReferences.clear();
+      VM.phantomReferences.clear();
+      rootTrace.prepare();
+      rcSpace.prepare(true);
+      if (CC_BACKUP_TRACE & performCycleCollection) {
+        backupTrace.prepare();
+      }
+      return;
+    }
+
+    if (phaseId == CLOSURE) {
+      rootTrace.prepare();
+      return;
+    }
+
+    if (phaseId == PROCESS_OLDROOTBUFFER) {
+      oldRootPool.prepare();
+      return;
+    }
+
+    if (phaseId == PROCESS_NEWROOTBUFFER) {
+      newRootPool.prepare();
+      return;
+    }
+
+    if (phaseId == PROCESS_MODBUFFER) {
+      modPool.prepare();
+      return;
+    }
+
+    if (phaseId == PROCESS_DECBUFFER) {
+      decPool.prepare();
+      return;
+    }
+
+    if (phaseId == BT_CLOSURE_INIT) {
+      if (CC_BACKUP_TRACE && performCycleCollection) {
+        newRootBackPool.prepare();
+      }
+      return;
+    }
+
+    if (phaseId == BT_CLOSURE) {
+      if (CC_BACKUP_TRACE && performCycleCollection) {
+        backupTrace.prepare();
+      }
+      return;
+    }
+
+    if (phaseId == RELEASE) {
+      rootTrace.release();
+      if (CC_BACKUP_TRACE && performCycleCollection) {
+        backupTrace.release();
+        rcloSpace.sweep(loFreeSweeper);
+        RCImmixObjectHeader.markValue = RCImmixObjectHeader.markValue.EQ(RCImmixObjectHeader.MARK_BIT_MASK)? Word.zero() : RCImmixObjectHeader.MARK_BIT_MASK;
+        RCImmixObjectHeader.markAllocValue = RCImmixObjectHeader.markAllocValue.EQ(RCImmixObjectHeader.MARK_BIT_MASK)? Word.zero() : RCImmixObjectHeader.MARK_BIT_MASK;
+      }
+      rcSpace.release(true);
+      int availablePages = getPagesAvail();
+      beginningPagesUsed = rcSpace.reservedPages();
+
+      // MAX heuristic for proactive copying
+      if (!performCycleCollection) {
+        for (int i = N-1; i >0; i--) {
+          a[i] = a[i-1];
+        }
+        a[0] = (rcSpace.linesUsed - rcSpace.linesCleaned) / rcSpace.linesUsed;
+      }
+
+      lineSurvivalRateExp = max();
+      if (lineSurvivalRateExp < 0.0f) lineSurvivalRateExp = 0;
+
+      rcSpace.linesUsed = 0;
+      rcSpace.linesCleaned = 0;
+
+      performCycleCollection =  availablePages < cycleTriggerThreshold;
+      performDefrag =  availablePages < defragTriggerThreshold;
+      RCImmixObjectHeader.performSurvivorCopy = false;
+
+      if (performCycleCollection) lineSurvivalRateExp = 0;
+
+      return;
+    }
+
+    super.collectionPhase(phaseId);
+  }
+
+  /*****************************************************************************
+   *
+   * Accounting
+   */
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  public int getPagesUsed() {
+    return (rcSpace.reservedPages() + rcloSpace.reservedPages() + super.getPagesUsed());
+  }
+
+  /**
+   * Return the number of pages reserved for collection.
+   */
+  @Override
+  public int getCollectionReserve() {
+    return super.getCollectionReserve() + rcSpace.defragHeadroomPages() + getCopyReserve();
+  }
+
+  /**
+   * Perform a linear scan across all objects in the heap to check for leaks.
+   */
+  @Override
+  public void sanityLinearScan(LinearScan scan) {
+    //rcSpace.linearScan(scan);
+  }
+
+  @Override
+  public int sanityExpectedRC(ObjectReference object, int sanityRootRC) {
+    if (isRCObject(object)) {
+      int fullRC = RCImmixObjectHeader.getRC(object);
+      if (fullRC == 0) {
+        return SanityChecker.DEAD;
+      }
+      if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(fullRC >= sanityRootRC);
+      return fullRC - sanityRootRC;
+    }
+    return SanityChecker.ALIVE;
+  }
+
+  @Override
+  public boolean willNeverMove(ObjectReference object) {
+    if (Space.isInSpace(REF_COUNT, object)) {
+      if (!VM.config.PINNING_BIT) return false;
+      RCImmixObjectHeader.pinObject(object);
+      return true;
+    } else if (Space.isInSpace(REF_COUNT_LOS, object)) {
+      return true;
+    }
+    return true;
+  }
+
+  /**
+   * Register specialized methods.
+   */
+  @Override
+  @Interruptible
+  protected void registerSpecializedMethods() {
+    super.registerSpecializedMethods();
+  }
+
+  @Override
+  public void forceFullHeapCollection() {
+    performCycleCollection = true;
+    performDefrag = true;
+  }
+
+  @Inline
+  public int getCopyReserve() {
+    if (!RC_SURVIVOR_COPY) return 0;
+    double copyReserve = lineSurvivalRateExp * (rcSpace.reservedPages() - beginningPagesUsed) * Options.survivorCopyMultiplier.getValue();
+    int totalBlocks = (int)copyReserve/PAGES_IN_BLOCK;
+    return totalBlocks * PAGES_IN_BLOCK;
+  }
+
+  @Inline
+  public static double max() {
+    double max = a[0];
+    for (int i = 1; i < N;i++) {
+      if (a[i] > max) max = a[i];
+    }
+    return max;
+  }
+
+  @Override
+  public byte setBuildTimeGCByte(Address object, ObjectReference typeRef, int size) {
+    byte status = 0;
+    status |= RCImmixObjectHeader.UNLOGGED.toInt();
+    return status;
+  }
+}
+
diff -r ba76b741d3fe MMTk/src/org/mmtk/plan/rcimmix/RCImmixBTDefragTraceLocal.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/plan/rcimmix/RCImmixBTDefragTraceLocal.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,107 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.plan.rcimmix;
+
+import static org.mmtk.policy.rcimmix.RCImmixConstants.*;
+
+import org.mmtk.plan.Plan;
+import org.mmtk.plan.TraceLocal;
+import org.mmtk.plan.Trace;
+import org.mmtk.policy.Space;
+import org.mmtk.policy.rcimmix.RCImmixObjectHeader;
+import org.mmtk.vm.VM;
+import org.vmmagic.pragma.*;
+import org.vmmagic.unboxed.*;
+
+/**
+ * This class implements the thread-local functionality for a defragmenting
+ * transitive closure over an immix space.
+ */
+@Uninterruptible
+public final class RCImmixBTDefragTraceLocal extends TraceLocal {
+
+ /**
+   * Constructor
+   * @param trace TODO
+   * @param modBuffer TODO
+   */
+  public RCImmixBTDefragTraceLocal(Trace trace) {
+    super(trace);
+  }
+
+  /****************************************************************************
+   *
+   * Externally visible Object processing and tracing
+   */
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  public boolean isLive(ObjectReference object) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(RCImmix.rcSpace.inImmixDefragCollection());
+    if (object.isNull()) return false;
+    else if (Space.isInSpace(RCImmix.REF_COUNT, object)) {
+      return RCImmix.rcSpace.isLive(object);
+    } else return RCImmixObjectHeader.isMarked(object);
+  }
+
+  /**
+   * {@inheritDoc}<p>
+   *
+   * In this instance, we refer objects in the mark-sweep space to the
+   * immixSpace for tracing, and defer to the superclass for all others.
+   *
+   * @param object The object to be traced.
+   * @return The new reference to the same object instance.
+   */
+  @Override
+  @Inline
+  public ObjectReference traceObject(ObjectReference object) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(RCImmix.rcSpace.inImmixDefragCollection());
+    if (RCImmix.isRCObject(object)) {
+      if (Space.isInSpace(RCImmix.REF_COUNT, object)) {
+        return RCImmix.rcSpace.defragTraceObject(this, object, Plan.ALLOC_DEFAULT);
+      } else {
+        return RCImmix.rcSpace.defragTraceObject(this, object);
+      }
+    } else return object;
+  }
+
+  @Override
+  @Inline
+  protected void scanObject(ObjectReference object) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(RCImmix.rcSpace.inImmixDefragCollection());
+    super.scanObject(object);
+    if (MARK_LINE_AT_SCAN_TIME && Space.isInSpace(RCImmix.REF_COUNT, object))
+      RCImmixObjectHeader.testAndMarkLines(object);
+  }
+
+  /**
+   * Return {@code true} if this object is guaranteed not to move during this
+   * collection (i.e. this object is defintely not an unforwarded
+   * object).
+   *
+   * @param object
+   * @return {@code true} if this object is guaranteed not to move during this
+   *         collection.
+   */
+  @Override
+  @Inline
+  public boolean willNotMoveInCurrentCollection(ObjectReference object) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(RCImmix.rcSpace.inImmixDefragCollection());
+    if (Space.isInSpace(RCImmix.REF_COUNT, object))
+      return RCImmix.rcSpace.willNotMoveThisGC(object);
+    return true;
+  }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/plan/rcimmix/RCImmixBTLargeSweeper.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/plan/rcimmix/RCImmixBTLargeSweeper.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,35 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.plan.rcimmix;
+
+import org.mmtk.policy.ExplicitLargeObjectSpace;
+import org.mmtk.policy.rcimmix.RCImmixObjectHeader;
+import org.vmmagic.pragma.*;
+import org.vmmagic.unboxed.*;
+
+/**
+ * This class implements the freeing of large objects during a backup trace.
+ */
+@Uninterruptible
+public final class RCImmixBTLargeSweeper extends ExplicitLargeObjectSpace.Sweeper {
+
+  @Override
+  public boolean sweepLargeObject(ObjectReference object) {
+    if (!RCImmixObjectHeader.isMarked(object)) {
+      // Free the object
+      return true;
+    }
+    // retain the object.
+    return false;
+  }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/plan/rcimmix/RCImmixBTTraceLocal.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/plan/rcimmix/RCImmixBTTraceLocal.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,98 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.plan.rcimmix;
+
+import static org.mmtk.policy.rcimmix.RCImmixConstants.*;
+
+import org.mmtk.plan.TraceLocal;
+import org.mmtk.plan.Trace;
+import org.mmtk.policy.Space;
+import org.mmtk.policy.rcimmix.RCImmixObjectHeader;
+import org.mmtk.vm.VM;
+import org.vmmagic.pragma.*;
+import org.vmmagic.unboxed.*;
+
+/**
+ * This class implements the thread-local functionality for a transitive
+ * closure over an immix space.
+ */
+@Uninterruptible
+public final class RCImmixBTTraceLocal extends TraceLocal {
+
+  /**
+   * Constructor
+   *
+   * @param trace The trace associated with this trace local.
+   * @param modBuffer The modified objects buffer associated with this trace local.  Possibly null.
+   */
+  public RCImmixBTTraceLocal(Trace trace) {
+    super(trace);
+  }
+
+  /****************************************************************************
+   *
+   * Externally visible Object processing and tracing
+   */
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  public boolean isLive(ObjectReference object) {
+    if (object.isNull()) return false;
+    else if (Space.isInSpace(RCImmix.REF_COUNT, object)) {
+      return RCImmix.rcSpace.fastIsLive(object);
+    } else return RCImmixObjectHeader.isMarked(object);
+  }
+
+  /**
+   * {@inheritDoc}<p>
+   *
+   * In this instance, we refer objects in the mark-sweep space to the
+   * immixSpace for tracing, and defer to the superclass for all others.
+   *
+   * @param object The object to be traced.
+   * @return The new reference to the same object instance.
+   */
+  @Override
+  @Inline
+  public ObjectReference traceObject(ObjectReference object) {
+    if (RCImmix.isRCObject(object)) {
+      if (Space.isInSpace(RCImmix.REF_COUNT, object)) {
+        return RCImmix.rcSpace.fastTraceObjectAndLine(this, object);
+      } else {
+        return RCImmix.rcSpace.fastTraceObject(this, object);
+      }
+    } else return object;
+  }
+
+  @Override
+  @Inline
+  protected void scanObject(ObjectReference object) {
+    super.scanObject(object);
+    if (MARK_LINE_AT_SCAN_TIME && Space.isInSpace(RCImmix.REF_COUNT, object))
+      RCImmixObjectHeader.testAndMarkLines(object);
+  }
+
+  /**
+   * Ensure that the referenced object will not move from this point through
+   * to the end of the collection. This can involve forwarding the object
+   * if necessary.
+   */
+  @Override
+  @Inline
+  public boolean willNotMoveInCurrentCollection(ObjectReference object) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!RCImmix.rcSpace.inImmixDefragCollection());
+    return true;
+  }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/plan/rcimmix/RCImmixCollector.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/plan/rcimmix/RCImmixCollector.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,373 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.plan.rcimmix;
+
+
+import org.mmtk.plan.Phase;
+import org.mmtk.plan.Plan;
+import org.mmtk.plan.StopTheWorldCollector;
+import org.mmtk.plan.TraceLocal;
+import org.mmtk.plan.TransitiveClosure;
+import org.mmtk.policy.Space;
+import org.mmtk.policy.rcimmix.RCImmixCollectorLocal;
+import org.mmtk.policy.rcimmix.RCImmixObjectHeader;
+import org.mmtk.utility.ForwardingWord;
+import org.mmtk.utility.alloc.RCImmixAllocator;
+import org.mmtk.utility.deque.AddressDeque;
+import org.mmtk.utility.deque.ObjectReferenceDeque;
+import org.mmtk.vm.VM;
+import org.vmmagic.pragma.Inline;
+import org.vmmagic.pragma.Uninterruptible;
+import org.vmmagic.unboxed.Address;
+import org.vmmagic.unboxed.ObjectReference;
+import org.vmmagic.unboxed.Word;
+
+/**
+ * This class implements the collector context for RCImmix collector.
+ */
+@Uninterruptible
+public class RCImmixCollector extends StopTheWorldCollector {
+
+  /************************************************************************
+   * Initialization
+   */
+  protected final AddressDeque newRootPointerBuffer;
+  protected final AddressDeque newRootPointerBackBuffer;
+  public TraceLocal backupTrace;
+  private final RCImmixBTTraceLocal backTrace;
+  private final RCImmixBTDefragTraceLocal defragTrace;
+  private final ObjectReferenceDeque modBuffer;
+  private final ObjectReferenceDeque oldRootBuffer;
+  private final RCImmixDecBuffer decBuffer;
+  public final RCImmixZero zero;
+  protected RCImmixCollectorLocal rc;
+  protected final RCImmixAllocator copy;
+  protected final RCImmixAllocator young;
+  private final RCImmixRootSetTraceLocal rootTrace;
+  private final RCImmixModifiedProcessor modProcessor;
+
+  /**
+   * Constructor.
+   */
+  public RCImmixCollector() {
+    newRootPointerBuffer = new AddressDeque("new-root", global().newRootPool);
+    newRootPointerBackBuffer = new AddressDeque("new-root-back", global().newRootBackPool);
+    oldRootBuffer = new ObjectReferenceDeque("old-root", global().oldRootPool);
+    decBuffer = new RCImmixDecBuffer(global().decPool);
+    modBuffer = new ObjectReferenceDeque("mod buf", global().modPool);
+    backTrace = new RCImmixBTTraceLocal(global().backupTrace);
+    defragTrace = new RCImmixBTDefragTraceLocal(global().backupTrace);
+    zero = new RCImmixZero();
+    rc = new RCImmixCollectorLocal(RCImmix.rcSpace);
+    copy = new RCImmixAllocator(RCImmix.rcSpace, true, true);
+    young = new RCImmixAllocator(RCImmix.rcSpace, true, false);
+    rootTrace = new RCImmixRootSetTraceLocal(global().rootTrace, newRootPointerBuffer);
+    modProcessor = new RCImmixModifiedProcessor(this);
+  }
+
+  /**
+   * Get the modified processor to use.
+   */
+  protected final TransitiveClosure getModifiedProcessor() {
+    return modProcessor;
+  }
+
+  /**
+   * Get the root trace to use.
+   */
+  protected final TraceLocal getRootTrace() {
+    return rootTrace;
+  }
+
+  /****************************************************************************
+   *
+   * Collection
+   */
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  public void collect() {
+    Phase.beginNewPhaseStack(Phase.scheduleComplex(global().collection));
+  }
+
+  @Override
+  public void collectionPhase(short phaseId, boolean primary) {
+    if (phaseId == RCImmix.PREPARE) {
+      rc.prepare(true);
+      getRootTrace().prepare();
+      if (RCImmix.CC_BACKUP_TRACE && RCImmix.performCycleCollection) {
+        backupTrace = RCImmix.rcSpace.inImmixDefragCollection() ? defragTrace : backTrace;
+        backupTrace.prepare();
+        copy.reset();
+      } else {
+        young.reset();
+      }
+      return;
+    }
+
+    if (phaseId == RCImmix.ROOTS) {
+      VM.scanning.computeGlobalRoots(getCurrentTrace());
+      VM.scanning.computeStaticRoots(getCurrentTrace());
+      if (Plan.SCAN_BOOT_IMAGE && RCImmix.performCycleCollection) {
+        VM.scanning.computeBootImageRoots(getCurrentTrace());
+      }
+      return;
+    }
+
+    if (phaseId == RCImmix.CLOSURE) {
+      getRootTrace().completeTrace();
+      newRootPointerBuffer.flushLocal();
+      return;
+    }
+
+    if (phaseId == RCImmix.PROCESS_OLDROOTBUFFER) {
+      ObjectReference current;
+      while(!(current = oldRootBuffer.pop()).isNull()) {
+        decBuffer.push(current);
+      }
+      return;
+    }
+
+    if (phaseId == RCImmix.PROCESS_NEWROOTBUFFER) {
+      ObjectReference current;
+      Address address;
+      while(!newRootPointerBuffer.isEmpty()) {
+        address = newRootPointerBuffer.pop();
+        current = address.loadObjectReference();
+        if (RCImmix.isRCObject(current)) {
+          if (RCImmix.CC_BACKUP_TRACE && RCImmix.performCycleCollection) {
+            if (RCImmixObjectHeader.incRC(current) == RCImmixObjectHeader.INC_NEW) {
+              modBuffer.push(current);
+            }
+            newRootPointerBackBuffer.push(address);
+          } else {
+            if (RCImmix.RC_SURVIVOR_COPY) {
+              survivorCopy(address, current, true);
+            } else {
+              if (RCImmixObjectHeader.incRC(current) == RCImmixObjectHeader.INC_NEW) {
+                if (Space.isInSpace(RCImmix.REF_COUNT, current)) {
+                  RCImmixObjectHeader.incLines(current);
+                }
+                modBuffer.push(current);
+              }
+              oldRootBuffer.push(current);
+            }
+          }
+        }
+      }
+      modBuffer.flushLocal();
+      if (RCImmix.CC_BACKUP_TRACE && RCImmix.performCycleCollection) {
+        newRootPointerBackBuffer.flushLocal();
+      } else {
+        oldRootBuffer.flushLocal();
+      }
+      return;
+    }
+
+    if (phaseId == RCImmix.PROCESS_MODBUFFER) {
+      ObjectReference current;
+      while(!(current = modBuffer.pop()).isNull()) {
+        RCImmixObjectHeader.makeUnlogged(current);
+        VM.scanning.scanObject(getModifiedProcessor(), current);
+      }
+      return;
+    }
+
+    if (phaseId == RCImmix.PROCESS_DECBUFFER) {
+      ObjectReference current;
+      if (RCImmix.CC_BACKUP_TRACE && RCImmix.performCycleCollection) {
+        while(!(current = decBuffer.pop()).isNull()) {
+          if (RCImmixObjectHeader.isNew(current)) {
+            if (Space.isInSpace(RCImmix.REF_COUNT_LOS, current)) {
+              RCImmix.rcloSpace.free(current);
+            } else if (Space.isInSpace(RCImmix.IMMORTAL, current)) {
+              VM.scanning.scanObject(zero, current);
+            }
+          }
+        }
+        return;
+      }
+      while(!(current = decBuffer.pop()).isNull()) {
+        if (RCImmixObjectHeader.isNew(current)) {
+          if (Space.isInSpace(RCImmix.REF_COUNT_LOS, current)) {
+            RCImmix.rcloSpace.free(current);
+          } else if (Space.isInSpace(RCImmix.IMMORTAL, current)) {
+            VM.scanning.scanObject(zero, current);
+          }
+        } else {
+          if (RCImmixObjectHeader.decRC(current) == RCImmixObjectHeader.DEC_KILL) {
+            decBuffer.processChildren(current);
+            if (Space.isInSpace(RCImmix.REF_COUNT, current)) {
+              RCImmixObjectHeader.decLines(current);
+            } else if (Space.isInSpace(RCImmix.REF_COUNT_LOS, current)) {
+              RCImmix.rcloSpace.free(current);
+            } else if (Space.isInSpace(RCImmix.IMMORTAL, current)) {
+              VM.scanning.scanObject(zero, current);
+            }
+          }
+        }
+      }
+      return;
+    }
+
+    if (phaseId == RCImmix.BT_CLOSURE_INIT) {
+      if (RCImmix.CC_BACKUP_TRACE && RCImmix.performCycleCollection) {
+        ObjectReference current, newObject;
+        Address address;
+        while(!newRootPointerBackBuffer.isEmpty()) {
+          address = newRootPointerBackBuffer.pop();
+          current = address.loadObjectReference();
+          if (RCImmix.isRCObject(current)) {
+            newObject = backupTrace.traceObject(current);
+            if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!newObject.isNull());
+            address.store(newObject);
+          }
+        }
+      }
+      return;
+    }
+
+    if (phaseId == RCImmix.BT_CLOSURE) {
+      if (RCImmix.CC_BACKUP_TRACE && RCImmix.performCycleCollection) {
+        backupTrace.completeTrace();
+      }
+      return;
+    }
+
+    if (phaseId == RCImmix.RELEASE) {
+      if (RCImmix.CC_BACKUP_TRACE && RCImmix.performCycleCollection) {
+        backupTrace.release();
+      }
+      getRootTrace().release();
+      rc.release(true);
+      if (VM.VERIFY_ASSERTIONS) {
+        VM.assertions._assert(newRootPointerBuffer.isEmpty());
+        VM.assertions._assert(modBuffer.isEmpty());
+        VM.assertions._assert(decBuffer.isEmpty());
+      }
+      return;
+    }
+
+    super.collectionPhase(phaseId, primary);
+  }
+
+  /****************************************************************************
+   *
+   * Miscellaneous
+   */
+
+  /** @return The active global plan as an <code>RC</code> instance. */
+  @Inline
+  protected static RCImmix global() {
+    return (RCImmix) VM.activePlan.global();
+  }
+
+  @Override
+  public final TraceLocal getCurrentTrace() {
+    return getRootTrace();
+  }
+
+  /** @return The current modBuffer instance. */
+  @Inline
+  public final ObjectReferenceDeque getModBuffer() {
+    return modBuffer;
+  }
+
+   /****************************************************************************
+   *
+   * Collection-time allocation
+   */
+
+   /**
+    * {@inheritDoc}
+    */
+   @Override
+   @Inline
+   public Address allocCopy(ObjectReference original, int bytes,
+       int align, int offset, int allocator) {
+     if (VM.VERIFY_ASSERTIONS) {
+       VM.assertions._assert(bytes <= Plan.MAX_NON_LOS_COPY_BYTES);
+       VM.assertions._assert(allocator == RCImmix.ALLOC_DEFAULT);
+     }
+     if (RCImmix.performCycleCollection && RCImmix.rcSpace.inImmixDefragCollection()) {
+       return copy.alloc(bytes, align, offset);
+     } else return young.alloc(bytes, align, offset);
+   }
+
+
+   @Override
+   @Inline
+   public void postCopy(ObjectReference object, ObjectReference typeRef,
+       int bytes, int allocator) {
+     if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(allocator == RCImmix.ALLOC_DEFAULT);
+     if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(Space.isInSpace(RCImmix.REF_COUNT, object));
+     if (RCImmix.performCycleCollection && RCImmix.rcSpace.inImmixDefragCollection()) {
+       RCImmix.rcSpace.postCopy(object, bytes);
+
+       if (VM.VERIFY_ASSERTIONS) {
+         VM.assertions._assert(backupTrace.isLive(object));
+         VM.assertions._assert(backupTrace.willNotMoveInCurrentCollection(object));
+       }
+     } else {
+       RCImmix.rcSpace.postCopyYoungObject(object, bytes);
+     }
+   }
+
+   @Inline
+   public void survivorCopy(Address slot, ObjectReference object, boolean root) {
+     if (Space.isInSpace(RCImmix.REF_COUNT, object)) {
+       // Race to be the (potential) forwarder
+       Word priorStatusWord = ForwardingWord.attemptToForward(object);
+       if (ForwardingWord.stateIsForwardedOrBeingForwarded(priorStatusWord)) {
+         // We lost the race; the object is either forwarded or being forwarded by another thread.
+         ObjectReference rtn = ForwardingWord.spinAndGetForwardedObject(object, priorStatusWord);
+         RCImmixObjectHeader.incRCOld(rtn);
+         slot.store(rtn);
+         if (root) oldRootBuffer.push(rtn);
+       } else {
+         byte priorState = (byte) (priorStatusWord.toInt() & 0xFF);
+         // the object is unforwarded, either because this is the first thread to reach it, or because the object can't be forwarded
+         if (!RCImmixObjectHeader.isHeaderNew(priorStatusWord)) {
+           // the object has not been forwarded, but has the correct new state; unlock and return unmoved object
+           RCImmixObjectHeader.returnToPriorState(object, priorState); // return to uncontested state
+           RCImmixObjectHeader.incRCOld(object);
+           if (root) oldRootBuffer.push(object);
+         } else {
+           if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(RCImmixObjectHeader.isNew(object));
+           // we are the first to reach the object; forward it
+           if (RCImmixObjectHeader.incRC(object) == RCImmixObjectHeader.INC_NEW) {
+             // forward
+             ObjectReference newObject;
+             if (RCImmix.rcSpace.exhaustedCopySpace || RCImmixObjectHeader.isPinnedObject(object)) {
+               RCImmixObjectHeader.clearStateYoungObject(object);
+               newObject = object;
+             } else {
+               newObject = ForwardingWord.forwardObject(object, Plan.ALLOC_DEFAULT);
+             }
+             slot.store(newObject);
+             RCImmixObjectHeader.incLines(newObject);
+             modBuffer.push(newObject);
+             if (root) oldRootBuffer.push(newObject);
+           }
+         }
+       }
+     } else {
+       if (RCImmixObjectHeader.incRC(object) == RCImmixObjectHeader.INC_NEW) {
+         modBuffer.push(object);
+       }
+       if (root) oldRootBuffer.push(object);
+     }
+   }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/plan/rcimmix/RCImmixConstraints.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/plan/rcimmix/RCImmixConstraints.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,42 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.plan.rcimmix;
+
+import static org.mmtk.policy.rcimmix.RCImmixConstants.MAX_IMMIX_OBJECT_BYTES;
+
+import org.mmtk.plan.StopTheWorldConstraints;
+import org.vmmagic.pragma.*;
+
+/**
+ * This class and its subclasses communicate to the host VM/Runtime
+ * any features of the selected plan that it needs to know.  This is
+ * separate from the main Plan/PlanLocal class in order to bypass any
+ * issues with ordering of static initialization.
+ */
+@Uninterruptible
+public class RCImmixConstraints extends StopTheWorldConstraints {
+  @Override
+  public int gcHeaderBits() { return 8; }
+  @Override
+  public int gcHeaderWords() { return 0; }
+  @Override
+  public boolean needsObjectReferenceWriteBarrier() { return true; }
+  @Override
+  public boolean objectReferenceBulkCopySupported() { return true; }
+  @Override
+  public int maxNonLOSDefaultAllocBytes() { return MAX_IMMIX_OBJECT_BYTES;}
+  @Override
+  public boolean movesObjects() { return true;}
+  @Override
+  public int maxNonLOSCopyBytes() { return MAX_IMMIX_OBJECT_BYTES; }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/plan/rcimmix/RCImmixDecBuffer.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/plan/rcimmix/RCImmixDecBuffer.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,48 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.plan.rcimmix;
+
+import org.mmtk.utility.deque.*;
+
+import org.vmmagic.pragma.*;
+import org.vmmagic.unboxed.*;
+
+/**
+ * This class implements a dec-buffer for RCImmix collector
+ *
+ * @see org.mmtk.plan.TransitiveClosure
+ */
+@Uninterruptible
+public final class RCImmixDecBuffer extends ObjectReferenceBuffer {
+  /****************************************************************************
+   *
+   * Initialization
+   */
+
+  /**
+   * Constructor
+   *
+   * @param queue The shared deque that is used.
+   */
+  public RCImmixDecBuffer(SharedDeque queue) {
+    super("dec", queue);
+  }
+
+  @Override
+  @Inline
+  protected void process(ObjectReference object) {
+    if (RCImmix.isRCObject(object)) {
+      push(object);
+    }
+  }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/plan/rcimmix/RCImmixModifiedProcessor.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/plan/rcimmix/RCImmixModifiedProcessor.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,59 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.plan.rcimmix;
+
+import org.mmtk.plan.TransitiveClosure;
+import org.mmtk.policy.Space;
+import org.mmtk.policy.rcimmix.RCImmixObjectHeader;
+import org.vmmagic.pragma.*;
+import org.vmmagic.unboxed.*;
+
+/**
+ * This class is the fundamental mechanism for performing a
+ * transitive closure over an object graph.<p>
+ *
+ * @see org.mmtk.plan.TraceLocal
+ */
+@Uninterruptible
+public final class RCImmixModifiedProcessor extends TransitiveClosure {
+
+  private RCImmixCollector collector;
+
+  public RCImmixModifiedProcessor(RCImmixCollector ctor) {
+    this.collector = ctor;
+  }
+
+  @Override
+  @Inline
+  public void processEdge(ObjectReference source, Address slot) {
+    ObjectReference object = slot.loadObjectReference();
+    if (RCImmix.isRCObject(object)) {
+      if (RCImmix.CC_BACKUP_TRACE && RCImmix.performCycleCollection) {
+        if (RCImmixObjectHeader.remainRC(object) == RCImmixObjectHeader.INC_NEW) {
+          collector.getModBuffer().push(object);
+        }
+      } else {
+        if (RCImmix.RC_SURVIVOR_COPY) {
+          collector.survivorCopy(slot, object, false);
+        } else {
+          if (RCImmixObjectHeader.incRC(object) == RCImmixObjectHeader.INC_NEW) {
+            if (Space.isInSpace(RCImmix.REF_COUNT, object)) {
+              RCImmixObjectHeader.incLines(object);
+            }
+            collector.getModBuffer().push(object);
+          }
+        }
+      }
+    }
+  }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/plan/rcimmix/RCImmixMutator.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/plan/rcimmix/RCImmixMutator.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,262 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.plan.rcimmix;
+
+
+import static org.mmtk.policy.rcimmix.RCImmixConstants.BYTES_IN_LINE;
+
+import org.mmtk.plan.StopTheWorldMutator;
+import org.mmtk.policy.LargeObjectLocal;
+import org.mmtk.policy.Space;
+import org.mmtk.policy.rcimmix.RCImmixMutatorLocal;
+import org.mmtk.policy.rcimmix.RCImmixObjectHeader;
+import org.mmtk.utility.alloc.Allocator;
+import org.mmtk.utility.deque.ObjectReferenceDeque;
+import org.mmtk.vm.VM;
+import org.vmmagic.pragma.*;
+import org.vmmagic.unboxed.*;
+
+/**
+ * This class implements the mutator context for RCImmix collector.
+ */
+@Uninterruptible
+public class RCImmixMutator extends StopTheWorldMutator {
+
+  /************************************************************************
+   * Instance fields
+   */
+  protected final RCImmixMutatorLocal rc;
+  private final LargeObjectLocal rclos;
+  private final ObjectReferenceDeque modBuffer;
+  private final RCImmixDecBuffer decBuffer;
+
+  /************************************************************************
+   *
+   * Initialization
+   */
+
+  /**
+   * Constructor. One instance is created per physical processor.
+   */
+  public RCImmixMutator() {
+    rc = new RCImmixMutatorLocal(RCImmix.rcSpace, false);
+    rclos = new LargeObjectLocal(RCImmix.rcloSpace);
+    modBuffer = new ObjectReferenceDeque("mod", global().modPool);
+    decBuffer = new RCImmixDecBuffer(global().decPool);
+  }
+
+  /****************************************************************************
+   *
+   * Mutator-time allocation
+   */
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  @Inline
+  public Address alloc(int bytes, int align, int offset, int allocator, int site) {
+    switch (allocator) {
+      case RCImmix.ALLOC_DEFAULT:
+        return rc.alloc(bytes, align, offset);
+      case RCImmix.ALLOC_LOS:
+      case RCImmix.ALLOC_PRIMITIVE_LOS:
+      case RCImmix.ALLOC_LARGE_CODE:
+        return rclos.alloc(bytes, align, offset);
+      case RCImmix.ALLOC_NON_MOVING:
+      case RCImmix.ALLOC_CODE:
+      case RCImmix.ALLOC_IMMORTAL:
+        return super.alloc(bytes, align, offset, allocator, site);
+      default:
+        VM.assertions.fail("Allocator not understood by RC");
+        return Address.zero();
+    }
+  }
+
+  @Override
+  @Inline
+  public void postAlloc(ObjectReference ref, ObjectReference typeRef, int bytes, int allocator) {
+    switch (allocator) {
+      case RCImmix.ALLOC_DEFAULT:
+        if (bytes > BYTES_IN_LINE) RCImmixObjectHeader.initializeHeader(ref);
+        break;
+      case RCImmix.ALLOC_LOS:
+      case RCImmix.ALLOC_PRIMITIVE_LOS:
+      case RCImmix.ALLOC_LARGE_CODE:
+        decBuffer.push(ref);
+        RCImmix.rcloSpace.initializeHeader(ref, true);
+        RCImmixObjectHeader.initializeHeaderOther(ref, true);
+        return;
+      case RCImmix.ALLOC_NON_MOVING:
+      case RCImmix.ALLOC_CODE:
+      case RCImmix.ALLOC_IMMORTAL:
+        decBuffer.push(ref);
+        RCImmixObjectHeader.initializeHeaderOther(ref, true);
+        return;
+      default:
+        VM.assertions.fail("Allocator not understood by RC");
+        return;
+    }
+  }
+
+  @Override
+  public Allocator getAllocatorFromSpace(Space space) {
+    if (space == RCImmix.rcSpace) return rc;
+    if (space == RCImmix.rcloSpace) return rclos;
+    return super.getAllocatorFromSpace(space);
+  }
+
+  /****************************************************************************
+   *
+   * Collection
+   */
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  public void collectionPhase(short phaseId, boolean primary) {
+    if (phaseId == RCImmix.PREPARE) {
+      rc.prepare();
+      return;
+    }
+
+    if (phaseId == RCImmix.PROCESS_MODBUFFER) {
+      modBuffer.flushLocal();
+      return;
+    }
+
+    if (phaseId == RCImmix.PROCESS_DECBUFFER) {
+      decBuffer.flushLocal();
+      return;
+    }
+
+    if (phaseId == RCImmix.RELEASE) {
+      rc.release();
+      if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(modBuffer.isEmpty());
+      if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(decBuffer.isEmpty());
+      return;
+    }
+
+    super.collectionPhase(phaseId, primary);
+  }
+
+  @Override
+  public final void flushRememberedSets() {
+    decBuffer.flushLocal();
+    modBuffer.flushLocal();
+    assertRemsetsFlushed();
+  }
+
+  @Override
+  public final void assertRemsetsFlushed() {
+    if (VM.VERIFY_ASSERTIONS) {
+      VM.assertions._assert(decBuffer.isFlushed());
+      VM.assertions._assert(modBuffer.isFlushed());
+    }
+  }
+
+  @Override
+  public void flush() {
+    super.flush();
+  }
+
+  /****************************************************************************
+   *
+   * Write barriers.
+   */
+
+  /**
+   * {@inheritDoc}
+   */
+  @Override
+  @Inline
+  public void objectReferenceWrite(ObjectReference src, Address slot,
+                           ObjectReference tgt, Word metaDataA,
+                           Word metaDataB, int mode) {
+    if (RCImmixObjectHeader.logRequired(src)) {
+      coalescingWriteBarrierSlow(src);
+    }
+    VM.barriers.objectReferenceWrite(src,tgt,metaDataA, metaDataB, mode);
+  }
+
+  @Override
+  @Inline
+  public boolean objectReferenceTryCompareAndSwap(ObjectReference src, Address slot,
+                                               ObjectReference old, ObjectReference tgt, Word metaDataA,
+                                               Word metaDataB, int mode) {
+    if (RCImmixObjectHeader.logRequired(src)) {
+      coalescingWriteBarrierSlow(src);
+    }
+    return VM.barriers.objectReferenceTryCompareAndSwap(src,old,tgt,metaDataA,metaDataB,mode);
+  }
+
+  /**
+   * A number of references are about to be copied from object
+   * <code>src</code> to object <code>dst</code> (as in an array
+   * copy).  Thus, <code>dst</code> is the mutated object.  Take
+   * appropriate write barrier actions.<p>
+   *
+   * @param src The source of the values to be copied
+   * @param srcOffset The offset of the first source address, in
+   * bytes, relative to <code>src</code> (in principle, this could be
+   * negative).
+   * @param dst The mutated object, i.e. the destination of the copy.
+   * @param dstOffset The offset of the first destination address, in
+   * bytes relative to <code>tgt</code> (in principle, this could be
+   * negative).
+   * @param bytes The size of the region being copied, in bytes.
+   * @return True if the update was performed by the barrier, false if
+   * left to the caller (always false in this case).
+   */
+  @Override
+  @Inline
+  public boolean objectReferenceBulkCopy(ObjectReference src, Offset srcOffset,
+                              ObjectReference dst, Offset dstOffset, int bytes) {
+    if (RCImmixObjectHeader.logRequired(dst)) {
+      coalescingWriteBarrierSlow(dst);
+    }
+    return false;
+  }
+
+  /**
+   * Slow path of the coalescing write barrier.
+   *
+   * <p> Attempt to log the source object. If successful in racing for
+   * the log bit, push an entry into the modified buffer and add a
+   * decrement buffer entry for each referent object (in the RC space)
+   * before setting the header bit to indicate that it has finished
+   * logging (allowing others in the race to continue).
+   *
+   * @param srcObj The object being mutated
+   */
+  @NoInline
+  private void coalescingWriteBarrierSlow(ObjectReference srcObj) {
+    if (RCImmixObjectHeader.attemptToLog(srcObj)) {
+      modBuffer.push(srcObj);
+      decBuffer.processChildren(srcObj);
+      RCImmixObjectHeader.makeLogged(srcObj);
+    }
+  }
+
+  /****************************************************************************
+   *
+   * Miscellaneous
+   */
+
+  /** @return The active global plan as an <code>RC</code> instance. */
+  @Inline
+  private static RCImmix global() {
+    return (RCImmix) VM.activePlan.global();
+  }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/plan/rcimmix/RCImmixRootSetTraceLocal.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/plan/rcimmix/RCImmixRootSetTraceLocal.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,78 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.plan.rcimmix;
+
+import org.mmtk.plan.TraceLocal;
+import org.mmtk.plan.Trace;
+import org.mmtk.policy.rcimmix.RCImmixObjectHeader;
+import org.mmtk.utility.deque.AddressDeque;
+import org.vmmagic.pragma.*;
+import org.vmmagic.unboxed.*;
+
+/**
+ * This class implements the thread-local core functionality for a transitive
+ * closure over the heap graph.
+ */
+@Uninterruptible
+public final class RCImmixRootSetTraceLocal extends TraceLocal {
+
+  private final AddressDeque rootPointerBuffer;
+
+  /**
+   * Constructor
+   */
+  public RCImmixRootSetTraceLocal(Trace trace, AddressDeque rootPointerBuffer) {
+    super(trace);
+    this.rootPointerBuffer = rootPointerBuffer;
+  }
+
+  /****************************************************************************
+   *
+   * Externally visible Object processing and tracing
+   */
+
+  /**
+   * Is the specified object reachable?
+   *
+   * @param object The object.
+   * @return <code>true</code> if the object is reachable.
+   */
+  @Override
+  public boolean isLive(ObjectReference object) {
+    return RCImmix.isRCObject(object) && RCImmixObjectHeader.isLiveRC(object) || super.isLive(object);
+  }
+
+  /**
+   * When we trace a non-root object we do nothing.
+   *
+   * @param object The object to be traced.
+   * @return The new reference to the same object instance.
+   */
+  @Override
+  @Inline
+  public ObjectReference traceObject(ObjectReference object) {
+    return object;
+  }
+
+  @Override
+  @Inline
+  public void processRootEdge(Address slot, boolean untraced) {
+    if (!slot.isZero()) rootPointerBuffer.push(slot);
+  }
+
+  @Override
+  @Inline
+  public boolean willNotMoveInCurrentCollection(ObjectReference object) {
+    return true;
+  }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/plan/rcimmix/RCImmixZero.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/plan/rcimmix/RCImmixZero.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,35 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.plan.rcimmix;
+
+import org.mmtk.plan.TransitiveClosure;
+
+import org.vmmagic.pragma.*;
+import org.vmmagic.unboxed.*;
+
+/**
+ * This class is the fundamental mechanism for performing a
+ * transitive closure over an object graph.<p>
+ *
+ * @see org.mmtk.plan.TraceLocal
+ */
+@Uninterruptible
+public final class RCImmixZero extends TransitiveClosure {
+
+  @Override
+  @Inline
+  public void processEdge(ObjectReference source, Address slot) {
+    slot.store(ObjectReference.nullReference());
+  }
+}
+
diff -r ba76b741d3fe MMTk/src/org/mmtk/policy/rcimmix/RCImmixBlock.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/policy/rcimmix/RCImmixBlock.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,243 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.policy.rcimmix;
+
+import static org.mmtk.policy.rcimmix.RCImmixConstants.*;
+import static org.mmtk.utility.Constants.LOG_BYTES_IN_SHORT;
+
+import org.mmtk.vm.VM;
+import org.vmmagic.pragma.Uninterruptible;
+import org.vmmagic.unboxed.Address;
+import org.vmmagic.unboxed.Offset;
+
+/**
+ * This class defines operations over block-granularity meta-data
+ *
+ */
+@Uninterruptible
+public class RCImmixBlock {
+
+  public static Address align(final Address ptr) {
+    return ptr.toWord().and(BLOCK_MASK.not()).toAddress();
+  }
+
+  public static boolean isAligned(final Address address) {
+    return address.EQ(align(address));
+  }
+
+  private static int getChunkIndex(final Address block) {
+    return block.toWord().and(CHUNK_MASK).rshl(LOG_BYTES_IN_BLOCK).toInt();
+  }
+
+  /***************************************************************************
+   * Block marking
+   */
+  public static boolean isUnused(final Address address) {
+    return getBlockMarkState(address) == UNALLOCATED_BLOCK_STATE;
+  }
+
+  static boolean isUnusedState(Address cursor) {
+    return cursor.loadShort() == UNALLOCATED_BLOCK_STATE;
+  }
+
+  static short getMarkState(Address cursor) {
+    return cursor.loadShort();
+  }
+
+  static void setState(Address cursor, short value) {
+    cursor.store(value);
+  }
+
+
+  public static short getBlockMarkState(Address address) {
+    return getBlockMarkStateAddress(address).loadShort();
+  }
+
+  static void setBlockAsInUse(Address address) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(isUnused(address));
+    setBlockState(address, UNMARKED_BLOCK_STATE);
+  }
+
+  public static void setBlockAsReused(Address address) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!isUnused(address));
+    setBlockState(address, REUSED_BLOCK_STATE);
+  }
+
+  static void setBlockAsUnallocated(Address address) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!isUnused(address));
+    getBlockMarkStateAddress(address).store(UNALLOCATED_BLOCK_STATE);
+  }
+
+  private static void setBlockState(Address address, short value) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(value != UNALLOCATED_BLOCK_STATE);
+    getBlockMarkStateAddress(address).store(value);
+  }
+
+  static Address getBlockMarkStateAddress(Address address) {
+    Address chunk = RCImmixChunk.align(address);
+    int index = getChunkIndex(address);
+    Address rtn = chunk.plus(RCImmixChunk.BLOCK_STATE_TABLE_OFFSET).plus(index<<LOG_BYTES_IN_BLOCK_STATE_ENTRY);
+    if (VM.VERIFY_ASSERTIONS) {
+      Address block = chunk.plus(index<<LOG_BYTES_IN_BLOCK);
+      VM.assertions._assert(isAligned(block));
+      boolean valid = rtn.GE(chunk.plus(RCImmixChunk.BLOCK_STATE_TABLE_OFFSET)) && rtn.LT(chunk.plus(RCImmixChunk.BLOCK_STATE_TABLE_OFFSET+BLOCK_STATE_TABLE_BYTES));
+      VM.assertions._assert(valid);
+    }
+    return rtn;
+  }
+
+  /***************************************************************************
+   * Sweeping
+   */
+  static short sweepOneBlock(Address block, int[] markHistogram) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(isAligned(block));
+    final boolean unused = isUnused(block);
+    if (unused && !SANITY_CHECK_LINE_MARKS)
+      return 0;
+    short totalrc = 0;
+    byte lastValue = 0;
+    short spillCount = 0;
+    Address address = RCImmixLine.getRCAddress(RCImmixLine.align(block));
+    for (int index = 0; index < LINES_IN_BLOCK; index++) {
+      byte value = address.loadByte();
+      if (value >= RCImmixObjectHeader.LIVE_THRESHOLD) {
+        totalrc++;
+      } else if (lastValue >= RCImmixObjectHeader.LIVE_THRESHOLD) {
+        spillCount++;
+      }
+      lastValue = value;
+      address = address.plus(RCImmixLine.BYTES_IN_LINE_RC_ENTRY);
+    }
+    if (VM.VERIFY_ASSERTIONS) {
+      VM.assertions._assert(totalrc <= LINES_IN_BLOCK);
+      VM.assertions._assert(totalrc + spillCount <= LINES_IN_BLOCK);
+      VM.assertions._assert(totalrc == 0 || !isUnused(block));
+    }
+    getDefragStateAddress(block).store(spillCount);
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(totalrc >= spillCount);
+    markHistogram[spillCount] += totalrc;
+    totalrc = (short) (totalrc + spillCount);
+    return totalrc;
+  }
+
+  static short sweepOneBlockCycle(Address block, int[] markHistogram) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(isAligned(block));
+    final boolean unused = isUnused(block);
+    if (unused && !SANITY_CHECK_LINE_MARKS)
+      return 0;
+    short totalrc = 0;
+    byte lastValue = 0;
+    short spillCount = 0;
+    Address address = RCImmixLine.getRCAddress(RCImmixLine.align(block));
+    for (int index = 0; index < LINES_IN_BLOCK; index++) {
+      byte value = address.loadByte();
+      boolean isCurrentMarked = (value & RCImmixObjectHeader.LINE_MARK_BIT_MASK) == RCImmixObjectHeader.LINE_MARK_BIT_MASK;
+      boolean isLastMarked = (lastValue & RCImmixObjectHeader.LINE_MARK_BIT_MASK) == RCImmixObjectHeader.LINE_MARK_BIT_MASK;
+      if (isCurrentMarked) {
+        totalrc++;
+        address.store((byte) (value & ~RCImmixObjectHeader.LINE_MARK_BIT_MASK));
+      } else if (isLastMarked) {
+        spillCount++;
+      }
+      if (!isCurrentMarked) {
+        value = RCImmixObjectHeader.ZERO;
+        address.store(value);
+      }
+      lastValue = value;
+      address = address.plus(RCImmixLine.BYTES_IN_LINE_RC_ENTRY);
+    }
+    if (VM.VERIFY_ASSERTIONS) {
+      VM.assertions._assert(totalrc <= LINES_IN_BLOCK);
+      VM.assertions._assert(totalrc + spillCount <= LINES_IN_BLOCK);
+      VM.assertions._assert(totalrc == 0 || !isUnused(block));
+    }
+    getDefragStateAddress(block).store(spillCount);
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(totalrc >= spillCount);
+    markHistogram[spillCount] += totalrc;
+    totalrc = (short) (totalrc + spillCount);
+    return totalrc;
+  }
+
+  /****************************************************************************
+   * Block defrag state
+   */
+
+  public static boolean isDefragSource(Address address) {
+    return getDefragStateAddress(address).loadShort() == BLOCK_IS_DEFRAG_SOURCE;
+  }
+
+  static void clearConservativeSpillCount(Address address) {
+    getDefragStateAddress(address).store((short) 0);
+  }
+
+  static short getConservativeSpillCount(Address address) {
+    return getDefragStateAddress(address).loadShort();
+  }
+
+  static Address getDefragStateAddress(Address address) {
+    Address chunk = RCImmixChunk.align(address);
+    int index = getChunkIndex(address);
+    Address rtn = chunk.plus(RCImmixChunk.BLOCK_DEFRAG_STATE_TABLE_OFFSET).plus(index<<LOG_BYTES_IN_BLOCK_DEFRAG_STATE_ENTRY);
+    if (VM.VERIFY_ASSERTIONS) {
+      Address block = chunk.plus(index<<LOG_BYTES_IN_BLOCK);
+      VM.assertions._assert(isAligned(block));
+      boolean valid = rtn.GE(chunk.plus(RCImmixChunk.BLOCK_DEFRAG_STATE_TABLE_OFFSET)) && rtn.LT(chunk.plus(RCImmixChunk.BLOCK_DEFRAG_STATE_TABLE_OFFSET+BLOCK_DEFRAG_STATE_TABLE_BYTES));
+      VM.assertions._assert(valid);
+    }
+    return rtn;
+  }
+
+  static void resetLineMarksAndDefragStateTable(short threshold, Address markStateBase, Address defragStateBase,
+      int block) {
+    Offset csOffset = Offset.fromIntZeroExtend(block<<LOG_BYTES_IN_BLOCK_DEFRAG_STATE_ENTRY);
+    short state = defragStateBase.loadShort(csOffset);
+    short defragState = BLOCK_IS_NOT_DEFRAG_SOURCE;
+    if (state >= threshold) defragState = BLOCK_IS_DEFRAG_SOURCE;
+    defragStateBase.store(defragState, csOffset);
+  }
+
+  public static Address getRCAddress(Address address) {
+    Address chunk = RCImmixChunk.align(address);
+    int index = getChunkIndex(address);
+    Address rtn = chunk.plus(RCImmixChunk.BLOCK_RC_TABLE_OFFSET).plus(index<<LOG_BYTES_IN_BLOCK_RC_ENTRY);
+    if (VM.VERIFY_ASSERTIONS) {
+      Address block = chunk.plus(index<<LOG_BYTES_IN_BLOCK);
+      VM.assertions._assert(isAligned(block));
+      boolean valid = rtn.GE(chunk.plus(RCImmixChunk.BLOCK_RC_TABLE_OFFSET)) && rtn.LT(chunk.plus(RCImmixChunk.BLOCK_RC_TABLE_OFFSET+BLOCK_RC_TABLE_BYTES));
+      VM.assertions._assert(valid);
+    }
+    return rtn;
+  }
+
+  private static final short UNALLOCATED_BLOCK_STATE = 0;
+  private static final short UNMARKED_BLOCK_STATE = (short) (MAX_BLOCK_MARK_STATE + 1);
+  private static final short REUSED_BLOCK_STATE = (short) (MAX_BLOCK_MARK_STATE + 2);
+
+  private static final short BLOCK_IS_NOT_DEFRAG_SOURCE = 0;
+  private static final short BLOCK_IS_DEFRAG_SOURCE = 1;
+
+  /* block states */
+  static final int LOG_BYTES_IN_BLOCK_STATE_ENTRY = LOG_BYTES_IN_SHORT; // use a short for now
+  static final int BYTES_IN_BLOCK_STATE_ENTRY = 1<<LOG_BYTES_IN_BLOCK_STATE_ENTRY;
+  static final int BLOCK_STATE_TABLE_BYTES = BLOCKS_IN_CHUNK<<LOG_BYTES_IN_BLOCK_STATE_ENTRY;
+
+  /* block rc states */
+  public static final int LOG_BYTES_IN_BLOCK_RC_ENTRY = 0;
+  static final int BYTES_IN_BLOCK_RC_ENTRY = 1<<LOG_BYTES_IN_BLOCK_RC_ENTRY;
+  static final int BLOCK_RC_TABLE_BYTES = BLOCKS_IN_CHUNK<<LOG_BYTES_IN_BLOCK_RC_ENTRY;
+
+  /* per-block defrag state */
+  static final int LOG_BYTES_IN_BLOCK_DEFRAG_STATE_ENTRY = LOG_BYTES_IN_SHORT;
+  static final int BYTES_IN_BLOCK_DEFRAG_STATE_ENTRY = 1<<LOG_BYTES_IN_BLOCK_DEFRAG_STATE_ENTRY;
+  static final int BLOCK_DEFRAG_STATE_TABLE_BYTES = BLOCKS_IN_CHUNK<<LOG_BYTES_IN_BLOCK_DEFRAG_STATE_ENTRY;
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/policy/rcimmix/RCImmixChunk.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/policy/rcimmix/RCImmixChunk.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,179 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.policy.rcimmix;
+
+import static org.mmtk.policy.Space.BYTES_IN_CHUNK;
+import static org.mmtk.utility.Constants.LOG_BYTES_IN_ADDRESS;
+import static org.mmtk.utility.Constants.LOG_BYTES_IN_INT;
+import static org.mmtk.utility.Constants.LOG_BYTES_IN_PAGE;
+import static org.mmtk.policy.rcimmix.RCImmixConstants.*;
+
+import org.mmtk.utility.Conversions;
+import org.mmtk.utility.heap.Mmapper;
+import org.mmtk.vm.VM;
+import org.vmmagic.pragma.Uninterruptible;
+import org.vmmagic.unboxed.Address;
+import org.vmmagic.unboxed.Extent;
+
+@Uninterruptible
+public class RCImmixChunk {
+
+  public static Address align(Address ptr) {
+    return ptr.toWord().and(CHUNK_MASK.not()).toAddress();
+  }
+
+  static boolean isAligned(Address ptr) {
+    return ptr.EQ(align(ptr));
+  }
+
+  static int getByteOffset(Address ptr) {
+    return ptr.toWord().and(CHUNK_MASK).toInt();
+  }
+
+  /**
+   * Return the number of pages of metadata required per chunk.
+   */
+  static int getRequiredMetaDataPages() {
+    Extent bytes = Extent.fromIntZeroExtend(ROUNDED_METADATA_BYTES_PER_CHUNK);
+    return Conversions.bytesToPagesUp(bytes);
+  }
+
+  static void sweep(Address chunk, Address end, RCImmixSpace space, int[] markHistogram) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(isAligned(chunk));
+    Address start = getFirstUsableBlock(chunk);
+    Address cursor = RCImmixBlock.getBlockMarkStateAddress(start);
+    for (int index = FIRST_USABLE_BLOCK_INDEX; index < BLOCKS_IN_CHUNK; index++) {
+      Address block = chunk.plus(index<<LOG_BYTES_IN_BLOCK);
+      if (block.GT(end)) break;
+      final boolean defragSource = space.inImmixDefragCollection() && RCImmixBlock.isDefragSource(block);
+      short marked = 0;
+      if (RCImmixObjectHeader.performCycleCollection) {
+        marked = RCImmixBlock.sweepOneBlockCycle(block, markHistogram);
+      } else {
+        marked = RCImmixBlock.sweepOneBlock(block, markHistogram);
+      }
+      if (marked == 0) {
+        if (!RCImmixBlock.isUnusedState(cursor)) {
+          space.release(block);
+          if (defragSource) RCImmixDefrag.defragBytesFreed.inc(BYTES_IN_BLOCK);
+        }
+        if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(RCImmixBlock.isUnused(block));
+      } else {
+        if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(marked > 0 && marked <= LINES_IN_BLOCK);
+        RCImmixBlock.setState(cursor, marked);
+        if (RCImmixBlock.getRCAddress(block).loadByte() == RCImmixObjectHeader.ZERO) {
+          space.linesCleaned += (LINES_IN_BLOCK - marked);
+        }
+        RCImmixBlock.getRCAddress(block).store(RCImmixObjectHeader.ONE);
+        if (defragSource) RCImmixDefrag.defragBytesNotFreed.inc(BYTES_IN_BLOCK);
+      }
+      if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(RCImmixBlock.isUnused(block) || (RCImmixBlock.getBlockMarkState(block) == marked && marked > 0 && marked <= MAX_BLOCK_MARK_STATE));
+      cursor = cursor.plus(RCImmixBlock.BYTES_IN_BLOCK_STATE_ENTRY);
+    }
+  }
+
+
+  static void clearMetaData(Address chunk) {
+    if (VM.VERIFY_ASSERTIONS) {
+      VM.assertions._assert(isAligned(chunk));
+      VM.assertions._assert(Conversions.isPageAligned(chunk));
+      VM.assertions._assert(Conversions.isPageAligned(ROUNDED_METADATA_BYTES_PER_CHUNK));
+    }
+    Mmapper.ensureMapped(chunk, ROUNDED_METADATA_PAGES_PER_CHUNK);
+    VM.memory.zero(false, chunk, Extent.fromIntZeroExtend(ROUNDED_METADATA_BYTES_PER_CHUNK));
+    if (VM.VERIFY_ASSERTIONS) checkMetaDataCleared(chunk, chunk);
+  }
+
+  private static void checkMetaDataCleared(Address chunk, Address value) {
+    VM.assertions._assert(isAligned(chunk));
+    Address block = RCImmixChunk.getHighWater(chunk);
+    if (value.EQ(chunk)) {
+      VM.assertions._assert(block.isZero());
+      block = chunk.plus(RCImmixChunk.ROUNDED_METADATA_BYTES_PER_CHUNK);
+    } else {
+      block = block.plus(BYTES_IN_BLOCK); // start at first block after highwater
+      VM.assertions._assert(RCImmixBlock.align(block).EQ(block));
+    }
+    while (block.LT(chunk.plus(BYTES_IN_CHUNK))) {
+      VM.assertions._assert(RCImmixChunk.align(block).EQ(chunk));
+      VM.assertions._assert(RCImmixBlock.isUnused(block));
+      block = block.plus(BYTES_IN_BLOCK);
+    }
+  }
+
+  static void updateHighWater(Address value) {
+    Address chunk = align(value);
+    if (getHighWater(chunk).LT(value)) {
+      setHighWater(chunk, value);
+    }
+  }
+
+  private static void setHighWater(Address chunk, Address value) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(isAligned(chunk));
+    chunk.plus(HIGHWATER_OFFSET).store(value);
+  }
+
+  public static Address getHighWater(Address chunk) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(isAligned(chunk));
+    return chunk.plus(HIGHWATER_OFFSET).loadAddress();
+  }
+
+  static void setMap(Address chunk, int value) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(isAligned(chunk));
+    chunk.plus(MAP_OFFSET).store(value);
+  }
+
+  static int getMap(Address chunk) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(isAligned(chunk));
+    int rtn = chunk.plus(MAP_OFFSET).loadInt();
+    return (rtn < 0) ? -rtn : rtn;
+  }
+
+  static void resetLineMarksAndDefragStateTable(Address chunk, short threshold) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(isAligned(chunk));
+    Address markStateBase = RCImmixBlock.getBlockMarkStateAddress(chunk);
+    Address defragStateBase = RCImmixBlock.getDefragStateAddress(chunk);
+    for (int b = FIRST_USABLE_BLOCK_INDEX; b < BLOCKS_IN_CHUNK; b++) {
+      RCImmixBlock.resetLineMarksAndDefragStateTable(threshold, markStateBase, defragStateBase, b);
+    }
+  }
+
+  static Address getFirstUsableBlock(Address chunk) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(isAligned(chunk));
+    Address rtn = chunk.plus(ROUNDED_METADATA_BYTES_PER_CHUNK);
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(rtn.EQ(RCImmixBlock.align(rtn)));
+    return rtn;
+  }
+
+  private static final int LOG_BYTES_IN_HIGHWATER_ENTRY = LOG_BYTES_IN_ADDRESS;
+  private static final int HIGHWATER_BYTES = 1<<LOG_BYTES_IN_HIGHWATER_ENTRY;
+  private static final int LOG_BYTES_IN_MAP_ENTRY = LOG_BYTES_IN_INT;
+  private static final int MAP_BYTES = 1<<LOG_BYTES_IN_MAP_ENTRY;
+
+  /* byte offsets for each type of metadata */
+  static final int LINE_RC_TABLE_OFFSET = 0;
+  static final int BLOCK_STATE_TABLE_OFFSET = LINE_RC_TABLE_OFFSET + RCImmixLine.LINE_RC_TABLE_BYTES;
+  static final int BLOCK_RC_TABLE_OFFSET = BLOCK_STATE_TABLE_OFFSET + RCImmixBlock.BLOCK_STATE_TABLE_BYTES;
+  static final int BLOCK_DEFRAG_STATE_TABLE_OFFSET = BLOCK_RC_TABLE_OFFSET + RCImmixBlock.BLOCK_RC_TABLE_BYTES;
+  static final int HIGHWATER_OFFSET = BLOCK_DEFRAG_STATE_TABLE_OFFSET + RCImmixBlock.BLOCK_DEFRAG_STATE_TABLE_BYTES;
+
+  static final int MAP_OFFSET = HIGHWATER_OFFSET + HIGHWATER_BYTES;
+  static final int METADATA_BYTES_PER_CHUNK = MAP_OFFSET + MAP_BYTES;
+
+  /* FIXME we round the metadata up to block sizes just to ensure the underlying allocator gives us aligned requests */
+  private static final int BLOCK_MASK = (1<<LOG_BYTES_IN_BLOCK) - 1;
+  static final int ROUNDED_METADATA_BYTES_PER_CHUNK = (METADATA_BYTES_PER_CHUNK + BLOCK_MASK) & ~BLOCK_MASK;
+  static final int ROUNDED_METADATA_PAGES_PER_CHUNK = ROUNDED_METADATA_BYTES_PER_CHUNK>>LOG_BYTES_IN_PAGE;
+  public static final int FIRST_USABLE_BLOCK_INDEX = ROUNDED_METADATA_BYTES_PER_CHUNK>>LOG_BYTES_IN_BLOCK;
+
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/policy/rcimmix/RCImmixChunkList.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/policy/rcimmix/RCImmixChunkList.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,185 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.policy.rcimmix;
+
+import static org.mmtk.utility.Constants.BYTES_IN_PAGE;
+import static org.mmtk.utility.Constants.LOG_BYTES_IN_ADDRESS;
+
+import org.mmtk.plan.Plan;
+import org.mmtk.policy.Space;
+import org.mmtk.vm.VM;
+import org.vmmagic.pragma.Uninterruptible;
+import org.vmmagic.unboxed.Address;
+import org.vmmagic.unboxed.AddressArray;
+
+@Uninterruptible
+public final class RCImmixChunkList {
+  private static final int LOG_PAGES_IN_CHUNK_MAP_BLOCK = 0;
+  private static final int ENTRIES_IN_CHUNK_MAP_BLOCK = (BYTES_IN_PAGE<<LOG_PAGES_IN_CHUNK_MAP_BLOCK)>>LOG_BYTES_IN_ADDRESS;
+  private static final int CHUNK_MAP_BLOCKS = 1<<4;
+  private static final int MAX_ENTRIES_IN_CHUNK_MAP = ENTRIES_IN_CHUNK_MAP_BLOCK * CHUNK_MAP_BLOCKS;
+  private AddressArray chunkMap =  AddressArray.create(CHUNK_MAP_BLOCKS);
+  private int chunkMapLimit = -1;
+  private int chunkMapCursor = -1;
+
+  void reset() {
+    chunkMapLimit = chunkMapCursor;
+  }
+
+  public Address getHeadChunk() {
+    if (chunkMapLimit < 0)
+      return Address.zero();
+    else
+      return getMapAddress(0).loadAddress();
+  }
+
+  public Address getTailChunk() {
+    if (chunkMapLimit < 0)
+      return Address.zero();
+    else
+      return getMapAddress(chunkMapLimit).loadAddress();
+  }
+
+  void addNewChunkToMap(Address chunk) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(RCImmixChunk.isAligned(chunk));
+    if (chunkMapCursor == MAX_ENTRIES_IN_CHUNK_MAP - 1)
+      consolidateMap();
+    chunkMapCursor++;
+    int index = getChunkIndex(chunkMapCursor);
+    int map = getChunkMap(chunkMapCursor);
+    if (map >= CHUNK_MAP_BLOCKS) {
+      Space.printUsageMB();
+      VM.assertions.fail("Overflow of chunk map!");
+    }
+    if (chunkMap.get(map).isZero()) {
+      Address tmp = Plan.metaDataSpace.acquire(1<<LOG_PAGES_IN_CHUNK_MAP_BLOCK);
+      if (tmp.isZero()) {
+        Space.printUsageMB();
+        VM.assertions.fail("Failed to allocate space for chunk map.  Is metadata virtual memory exhausted?");
+      }
+      chunkMap.set(map, tmp);
+    }
+    Address entry = chunkMap.get(map).plus(index<<LOG_BYTES_IN_ADDRESS);
+    entry.store(chunk);
+    RCImmixChunk.setMap(chunk, chunkMapCursor);
+    if (VM.VERIFY_ASSERTIONS) checkMap();
+  }
+
+  void removeChunkFromMap(Address chunk) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(RCImmixChunk.isAligned(chunk));
+    int entry = RCImmixChunk.getMap(chunk);
+    getMapAddress(entry).store(Address.zero());  // zero it it
+    RCImmixChunk.setMap(chunk, -entry);
+    if (VM.VERIFY_ASSERTIONS) checkMap();
+  }
+
+  private int getChunkIndex(int entry) { return entry & (ENTRIES_IN_CHUNK_MAP_BLOCK - 1);}
+  private int getChunkMap(int entry) {return entry & ~(ENTRIES_IN_CHUNK_MAP_BLOCK - 1);}
+
+  private Address getMapAddress(int entry) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(entry >= 0);
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(entry <= chunkMapCursor);
+    int index = getChunkIndex(entry);
+    int map = getChunkMap(entry);
+    return chunkMap.get(map).plus(index<<LOG_BYTES_IN_ADDRESS);
+  }
+
+  /**
+   * A chunk iterator.  Return the next chunk in sequence, or null if the
+   * next chunk is the same chunk (ie there is only one chunk in the iterator).
+   *
+   * @param chunk The chunk
+   * @return The next chunk in the sequence, or null if next is chunk.
+   */
+  public Address nextChunk(Address chunk) {
+    return nextChunk(chunk, chunk);
+  }
+
+  /**
+   * A chunk iterator.  Return the next chunk in sequence, or null if the
+   * next chunk is limit.
+   *
+   * @param chunk The chunk
+   * @param limit The starting point (if next is equal to this, we're done)
+   * @return The next chunk in the sequence, or null if next is limit.
+   */
+  private Address nextChunk(final Address chunk, final Address limit) {
+    return nextChunk(chunk, RCImmixChunk.getMap(limit), 1);
+  }
+
+  /**
+   * A chunk iterator.  Return the next chunk in sequence, strided
+   * by stride steps, or null if the next chunk is start.
+   *
+   * @param chunk The chunk
+   * @param start The point where this iterator started, which defines its end-point
+   * @param stride The stride by which the iterator should be stepped
+   * @return The next chunk in the sequence, or null if next is start.
+   */
+  public Address nextChunk(final Address chunk, final int start, final int stride) {
+    if (VM.VERIFY_ASSERTIONS) checkMap();
+    return nextChunk(RCImmixChunk.getMap(chunk), start, stride);
+  }
+
+  /**
+   * A chunk iterator.  Return the next chunk in sequence, strided
+   * by stride steps, or null if the next chunk is start.
+   *
+   * @param entry The entry we're currently up to
+   * @param start The point where this iterator started, which defines its end-point
+   * @param stride The stride by which the iterator should be stepped
+   * @return The next chunk in the sequence, or null if next is start.
+   */
+  private Address nextChunk(int entry, final int start, final int stride) {
+    if (VM.VERIFY_ASSERTIONS) checkMap();
+    Address chunk;
+    do {
+      entry += stride;
+      if (entry > chunkMapLimit) { entry = entry % stride; }
+      chunk = getMapAddress(entry).loadAddress();
+    } while (chunk.isZero() && entry != start);
+    return entry == start ? Address.zero() : chunk;
+  }
+
+  public Address firstChunk(int ordinal, int stride) {
+    if (ordinal > chunkMapCursor) return Address.zero();
+    if (VM.VERIFY_ASSERTIONS) checkMap();
+    Address chunk = getMapAddress(ordinal).loadAddress();
+    return chunk.isZero() ? nextChunk(ordinal, ordinal, stride) : chunk;
+  }
+
+  private void checkMap() {
+    VM.assertions._assert(chunkMapLimit <= chunkMapCursor);
+    for (int entry = 0; entry <= chunkMapCursor; entry++) {
+      Address chunk = getMapAddress(entry).loadAddress();
+      if (!chunk.isZero())
+        VM.assertions._assert(RCImmixChunk.getMap(chunk) == entry);
+    }
+  }
+
+  public void consolidateMap() {
+    int oldCursor = 0;
+    int newCursor = -1;
+    while (oldCursor <= chunkMapCursor) {
+      Address chunk = getMapAddress(oldCursor).loadAddress();
+      if (!chunk.isZero()) {
+        getMapAddress(++newCursor).store(chunk);
+        RCImmixChunk.setMap(chunk, newCursor);
+      }
+      oldCursor++;
+    }
+    chunkMapCursor = newCursor;
+    chunkMapLimit = newCursor;
+    if (VM.VERIFY_ASSERTIONS) checkMap();
+  }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/policy/rcimmix/RCImmixCollectorLocal.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/policy/rcimmix/RCImmixCollectorLocal.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,111 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.policy.rcimmix;
+
+
+import org.mmtk.vm.VM;
+
+import org.vmmagic.pragma.*;
+import org.vmmagic.unboxed.Address;
+
+/**
+ * This class implements unsynchronized (local) elements of an
+ * immix collector.  Marking is done using both a bit in
+ * each header's object word, and a mark byte.  Sweeping is
+ * performed lazily.<p>
+ *
+ */
+@Uninterruptible
+public final class RCImmixCollectorLocal {
+
+  /****************************************************************************
+   *
+   * Class variables
+   */
+
+
+  /****************************************************************************
+   *
+   * Instance variables
+   */
+  private final RCImmixSpace rCImmixSpace;
+  private final RCImmixChunkList chunkMap;
+  private final RCImmixDefrag rCImmixDefrag;
+
+
+  /****************************************************************************
+   *
+   * Initialization
+   */
+
+  /**
+   * Constructor
+   *
+   * @param space The mark-sweep space to which this allocator
+   * instances is bound.
+   */
+  public RCImmixCollectorLocal(RCImmixSpace space) {
+    rCImmixSpace = space;
+    chunkMap = rCImmixSpace.getChunkMap();
+    rCImmixDefrag = rCImmixSpace.getDefrag();
+  }
+
+  /****************************************************************************
+   *
+   * Collection
+   */
+
+  /**
+   * Prepare for a collection. If paranoid, perform a sanity check.
+   */
+  public void prepare(boolean majorGC) {
+    int ordinal = VM.activePlan.collector().parallelWorkerOrdinal();
+    if (majorGC) {
+      if (rCImmixSpace.inImmixDefragCollection()) {
+        short threshold = RCImmixDefrag.defragSpillThreshold;
+        resetLineMarksAndDefragStateTable(ordinal, threshold);
+      }
+    }
+  }
+
+  private void resetLineMarksAndDefragStateTable(int ordinal, final short threshold) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(rCImmixSpace.inImmixDefragCollection());
+    int stride = VM.activePlan.collector().parallelWorkerCount();
+    Address chunk = chunkMap.firstChunk(ordinal, stride);
+    while (!chunk.isZero()) {
+      RCImmixChunk.resetLineMarksAndDefragStateTable(chunk, threshold);
+      chunk = chunkMap.nextChunk(chunk, ordinal, stride);
+    }
+  }
+
+
+  /**
+   * Finish up after a collection.
+   *
+   * We help sweeping all the blocks in parallel.
+   */
+  public void release(boolean majorGC) {
+    sweepAllBlocks(majorGC);
+  }
+
+  private void sweepAllBlocks(boolean majorGC) {
+    int stride = VM.activePlan.collector().parallelWorkerCount();
+    int ordinal = VM.activePlan.collector().parallelWorkerOrdinal();
+    int[] markSpillHisto = rCImmixDefrag.getAndZeroSpillMarkHistogram(ordinal);
+    Address chunk = chunkMap.firstChunk(ordinal, stride);
+    while (!chunk.isZero()) {
+      RCImmixChunk.sweep(chunk, RCImmixChunk.getHighWater(chunk), rCImmixSpace, markSpillHisto);
+      chunk = chunkMap.nextChunk(chunk, ordinal, stride);
+    }
+  }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/policy/rcimmix/RCImmixConstants.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/policy/rcimmix/RCImmixConstants.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,78 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.policy.rcimmix;
+
+import static org.mmtk.policy.Space.BYTES_IN_CHUNK;
+import static org.mmtk.policy.Space.LOG_BYTES_IN_CHUNK;
+import static org.mmtk.utility.Constants.LOG_BYTES_IN_PAGE;
+
+import org.mmtk.plan.Plan;
+import org.vmmagic.unboxed.Word;
+
+public class RCImmixConstants {
+  public static final boolean BUILD_FOR_STICKYIMMIX = Plan.NEEDS_LOG_BIT_IN_HEADER;
+
+  /* start temporary experimental constants --- should not be allowed to lurk longer than necessary */
+  public static final int TMP_MIN_SPILL_THRESHOLD = 2;
+  public static final boolean PREFER_COPY_ON_NURSERY_GC = true;
+  /* end temporary experimental constants */
+
+  static final byte MAX_LINE_MARK_STATE = 127;
+  public static final byte RESET_LINE_MARK_STATE = 1;
+
+  public static final boolean MARK_LINE_AT_SCAN_TIME = true; // else do it at mark time
+
+  public static final boolean SANITY_CHECK_LINE_MARKS = false;
+
+  public static final float DEFAULT_LINE_REUSE_RATIO = (float) 0.99;
+  public static final float DEFAULT_DEFRAG_LINE_REUSE_RATIO = (float) 0.99;
+  public static final float DEFAULT_SIMPLE_SPILL_THRESHOLD = (float) 0.25;
+  public static final int DEFAULT_DEFRAG_HEADROOM = 0; // number of pages.
+  public static final float DEFAULT_DEFRAG_HEADROOM_FRACTION = (float) 0.020;
+  public static final int DEFAULT_DEFRAG_FREE_HEADROOM = 0; // number of pages.  This should only deviate from zero for analytical purposes.  Otherwise the defragmenter is cheating!
+  public static final float DEFAULT_DEFRAG_FREE_HEADROOM_FRACTION = (float) 0.0;
+  public static final float DEFAULT_SURVIVOR_COPY_MULTIPLIER = (float) 1.5;
+  /* sizes etc */
+  static final int LOG_BYTES_IN_BLOCK = (LOG_BYTES_IN_PAGE > 15 ? LOG_BYTES_IN_PAGE : 15);
+  public static final int BYTES_IN_BLOCK = 1<<LOG_BYTES_IN_BLOCK;
+  static final int LOG_PAGES_IN_BLOCK = LOG_BYTES_IN_BLOCK - LOG_BYTES_IN_PAGE;
+  public static final int PAGES_IN_BLOCK = 1<<LOG_PAGES_IN_BLOCK;
+  static final int LOG_BLOCKS_IN_CHUNK = LOG_BYTES_IN_CHUNK-LOG_BYTES_IN_BLOCK;
+  static final int BLOCKS_IN_CHUNK = 1<<LOG_BLOCKS_IN_CHUNK;
+
+  public static final int LOG_BYTES_IN_LINE = 8;
+  static final int LOG_LINES_IN_BLOCK = LOG_BYTES_IN_BLOCK - LOG_BYTES_IN_LINE;
+  public static final short LINES_IN_BLOCK = (short) (1<<LOG_LINES_IN_BLOCK);
+  static final int LOG_LINES_IN_CHUNK = LOG_BYTES_IN_CHUNK - LOG_BYTES_IN_LINE;
+  static final int LINES_IN_CHUNK = 1<<LOG_LINES_IN_CHUNK;
+
+  public static final int BYTES_IN_LINE = 1<<LOG_BYTES_IN_LINE;
+
+  public static final int MAX_IMMIX_OBJECT_BYTES = BYTES_IN_BLOCK>>1;
+
+  private static final int LOG_BLOCKS_IN_RECYCLE_ALLOC_CHUNK = 4; // 3 + 15 -> 19 (512KB)
+  private static final int LOG_BYTES_IN_RECYCLE_ALLOC_CHUNK = LOG_BLOCKS_IN_RECYCLE_ALLOC_CHUNK + LOG_BYTES_IN_BLOCK;
+  static final int BYTES_IN_RECYCLE_ALLOC_CHUNK = 1<<LOG_BYTES_IN_RECYCLE_ALLOC_CHUNK;
+
+  public static final short MAX_BLOCK_MARK_STATE = LINES_IN_BLOCK;
+         static final short MAX_CONSV_SPILL_COUNT = (short) (LINES_IN_BLOCK/2);
+  public static final short SPILL_HISTOGRAM_BUCKETS = (short) (MAX_CONSV_SPILL_COUNT + 1);
+  public static final short MARK_HISTOGRAM_BUCKETS = (short) (LINES_IN_BLOCK + 1);
+         static final short MAX_COLLECTORS = 16; // nothing special here---we can increase this at the cost of a few hundred bites at build time.
+
+  public static final Word RECYCLE_ALLOC_CHUNK_MASK = Word.fromIntZeroExtend(BYTES_IN_RECYCLE_ALLOC_CHUNK - 1);
+  protected static final Word CHUNK_MASK = Word.fromIntZeroExtend(BYTES_IN_CHUNK - 1);
+  public static final Word BLOCK_MASK = Word.fromIntZeroExtend(BYTES_IN_BLOCK - 1);
+  protected static final Word LINE_MASK = Word.fromIntZeroExtend(BYTES_IN_LINE - 1);
+
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/policy/rcimmix/RCImmixDefrag.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/policy/rcimmix/RCImmixDefrag.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,184 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+
+package org.mmtk.policy.rcimmix;
+
+import static org.mmtk.policy.rcimmix.RCImmixConstants.*;
+import static org.mmtk.utility.Constants.LOG_BYTES_IN_PAGE;
+
+import org.mmtk.utility.Log;
+import org.mmtk.utility.heap.FreeListPageResource;
+import org.mmtk.utility.options.DefragFreeHeadroom;
+import org.mmtk.utility.options.DefragFreeHeadroomFraction;
+import org.mmtk.utility.options.DefragHeadroom;
+import org.mmtk.utility.options.DefragHeadroomFraction;
+import org.mmtk.utility.options.DefragLineReuseRatio;
+import org.mmtk.utility.options.DefragSimpleSpillThreshold;
+import org.mmtk.utility.options.DefragStress;
+import org.mmtk.utility.options.Options;
+import org.mmtk.utility.statistics.EventCounter;
+import org.mmtk.utility.statistics.SizeCounter;
+import org.mmtk.vm.VM;
+import org.vmmagic.pragma.Uninterruptible;
+
+@Uninterruptible
+public class RCImmixDefrag {
+  private boolean inDefragCollection = false;
+  //private int debugBytesDefraged = 0;
+  private int availableCleanPagesForDefrag;
+  private boolean defragSpaceExhausted = true;
+  private int[][] spillMarkHistograms = new int[MAX_COLLECTORS][SPILL_HISTOGRAM_BUCKETS];
+  private int[] spillAvailHistogram = new int[SPILL_HISTOGRAM_BUCKETS];
+  public static SizeCounter defragCleanBytesUsed = new SizeCounter("cleanUsed");
+
+  /* verbose stats (used only on stats runs since they induce overhead when gathered) */
+  public static SizeCounter defragBytesNotFreed = new SizeCounter("bytesNotFreed");
+  public static SizeCounter defragBytesFreed = new SizeCounter("bytesFreed");
+  public static SizeCounter defragCleanBytesAvailable = new SizeCounter("cleanAvail");
+
+  private final FreeListPageResource pr;
+  private boolean debugCollectionTypeDetermined = false;
+  static short defragSpillThreshold = 0;
+  static short defragReusableMarkStateThreshold = 0;
+  public static EventCounter defrags = new EventCounter("defrags");
+
+  static {
+    Options.defragLineReuseRatio = new DefragLineReuseRatio();
+    Options.defragHeadroom = new DefragHeadroom();
+    Options.defragHeadroomFraction = new DefragHeadroomFraction();
+    Options.defragFreeHeadroom = new DefragFreeHeadroom();
+    Options.defragFreeHeadroomFraction = new DefragFreeHeadroomFraction();
+    Options.defragSimpleSpillThreshold = new DefragSimpleSpillThreshold();
+    Options.defragStress = new DefragStress();
+    defragReusableMarkStateThreshold = (short) (Options.defragLineReuseRatio.getValue() * MAX_BLOCK_MARK_STATE);
+  }
+
+  RCImmixDefrag(FreeListPageResource pr) {
+    this.pr = pr;
+  }
+
+  boolean inDefrag() { return inDefragCollection; }
+
+  void prepare(RCImmixChunkList chunkMap, RCImmixSpace space) {
+    availableCleanPagesForDefrag = VM.activePlan.global().getTotalPages() - VM.activePlan.global().getPagesReserved() + getDefragHeadroomPages();
+    if (availableCleanPagesForDefrag < 0) availableCleanPagesForDefrag = 0;
+    defragSpaceExhausted = false;
+
+    /* Free defrag pages (not budgeted, used for experimentation) */
+    if (Options.defragFreeHeadroom.getPages() > 0) {
+      availableCleanPagesForDefrag += Options.defragFreeHeadroom.getPages();
+    } else if (Options.defragFreeHeadroomFraction.getValue() > 0) {
+      availableCleanPagesForDefrag += (int) (pr.reservedPages() * Options.defragFreeHeadroomFraction.getValue());
+    }
+
+    if (inDefragCollection) {
+      if (Options.verbose.getValue() > 0) {
+        Log.write("[Defrag]");
+      }
+      chunkMap.consolidateMap();
+      establishDefragSpillThreshold(chunkMap, space);
+      defrags.inc();
+      defragCleanBytesAvailable.inc(availableCleanPagesForDefrag<<LOG_BYTES_IN_PAGE);
+    }
+    availableCleanPagesForDefrag += VM.activePlan.global().getCollectionReserve();
+  }
+
+  void globalRelease() {
+    if (inDefragCollection && Options.verbose.getValue() > 2) {
+      Log.write("(Defrag summary: cu: "); defragCleanBytesUsed.printCurrentVolume();
+      Log.write(" nf: "); defragBytesNotFreed.printCurrentVolume();
+      Log.write(" fr: "); defragBytesFreed.printCurrentVolume();
+      Log.write(" av: "); defragCleanBytesAvailable.printCurrentVolume();
+      Log.write(")");
+    }
+
+    inDefragCollection = false;
+    debugCollectionTypeDetermined = false;
+  }
+
+  int getDefragHeadroomPages() {
+    if (Options.defragHeadroom.getPages() > 0) {
+      return Options.defragHeadroom.getPages();
+    } else if (Options.defragHeadroomFraction.getValue() > 0) {
+      return (int) (pr.reservedPages() * Options.defragHeadroomFraction.getValue());
+    }
+    return 0;
+  }
+
+  void decideWhetherToDefrag(boolean emergencyCollection, boolean collectWholeHeap, int collectionAttempt, boolean userTriggered, boolean exhaustedReusableSpace, boolean forceDefrag) {
+    if (forceDefrag) {
+      inDefragCollection = true;
+    } else {
+      inDefragCollection =  (collectionAttempt > 1) ||
+          emergencyCollection ||
+          collectWholeHeap && (Options.defragStress.getValue() || (userTriggered && Options.fullHeapSystemGC.getValue()));
+    }
+    /*if (inDefragCollection) {
+      debugBytesDefraged = 0;
+    }*/
+    debugCollectionTypeDetermined = true;
+  }
+
+  boolean determined(boolean inDefrag) { return debugCollectionTypeDetermined && !(inDefrag ^ inDefragCollection); }
+
+  void getBlock() {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!inDefragCollection || !defragSpaceExhausted);
+    if (availableCleanPagesForDefrag <= 0)
+      defragSpaceExhausted = true;
+    availableCleanPagesForDefrag -= PAGES_IN_BLOCK;
+    //debugBytesDefraged += BYTES_IN_BLOCK;
+    RCImmixDefrag.defragCleanBytesUsed.inc(BYTES_IN_BLOCK);
+  }
+
+  private void establishDefragSpillThreshold(RCImmixChunkList chunkMap, RCImmixSpace space) {
+    int cleanLines = space.getAvailableLines(spillAvailHistogram);
+    int availableLines = cleanLines + availableCleanPagesForDefrag<<(LOG_BYTES_IN_PAGE - LOG_BYTES_IN_LINE);
+
+    int requiredLines = 0;
+    short threshold = (short) MAX_CONSV_SPILL_COUNT;
+    int limit = (int) (availableLines / Options.defragLineReuseRatio.getValue());
+    if (VM.VERIFY_ASSERTIONS && Options.verbose.getValue() > 2) {
+      Log.write("[threshold: "); Log.write("cl: "); Log.write(cleanLines);
+      Log.write(" al: "); Log.write(availableLines);
+      Log.write(" lm: "); Log.write(limit);
+    }
+    int collectors = VM.activePlan.collectorCount();
+    for (short index = MAX_CONSV_SPILL_COUNT; index >= TMP_MIN_SPILL_THRESHOLD && limit > requiredLines; index--) {
+      threshold = (short) index;
+      int thisBucketMark = 0;
+      int thisBucketAvail = 0;
+      for (int c = 0; c < collectors; c++) thisBucketMark += spillMarkHistograms[c][threshold];
+
+      thisBucketAvail = spillAvailHistogram[threshold];
+      limit -= thisBucketAvail;
+      requiredLines += thisBucketMark;
+      if (VM.VERIFY_ASSERTIONS && Options.verbose.getValue() > 2) {
+        Log.write(" ("); Log.write(index); Log.write(" "); Log.write(limit); Log.write(","); Log.write(requiredLines); Log.write(")");
+      }
+    }
+    if (VM.VERIFY_ASSERTIONS && Options.verbose.getValue() > 2) {
+      Log.write(" threshold: "); Log.write(threshold); Log.write("]");
+    }
+    defragSpillThreshold = threshold;
+  }
+
+
+  boolean spaceExhausted() { return defragSpaceExhausted; }
+
+  int[] getAndZeroSpillMarkHistogram(int ordinal) {
+    int[] rtn = spillMarkHistograms[ordinal];
+    for (int i = 0; i < SPILL_HISTOGRAM_BUCKETS; i++)
+      rtn[i] = 0;
+    return rtn;
+  }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/policy/rcimmix/RCImmixLine.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/policy/rcimmix/RCImmixLine.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,100 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.policy.rcimmix;
+
+import static org.mmtk.policy.rcimmix.RCImmixConstants.*;
+
+import org.mmtk.vm.VM;
+import org.vmmagic.pragma.Inline;
+import org.vmmagic.pragma.Uninterruptible;
+import org.vmmagic.unboxed.Address;
+import org.vmmagic.unboxed.Extent;
+
+@Uninterruptible
+public class RCImmixLine {
+
+  public static Address align(Address ptr) {
+    return ptr.toWord().and(LINE_MASK.not()).toAddress();
+  }
+
+  public static boolean isAligned(Address address) {
+    return address.EQ(align(address));
+  }
+
+  static int getChunkIndex(Address line) {
+    return line.toWord().and(CHUNK_MASK).rshl(LOG_BYTES_IN_LINE).toInt();
+  }
+
+  @Inline
+  public static int getNextUnavailable(Address blockAddress, int line) {
+    Address lineAddress = blockAddress.plus(Extent.fromIntZeroExtend(line<<LOG_BYTES_IN_LINE));
+    lineAddress = RCImmixLine.align(lineAddress);
+    Address lineRCAddress = RCImmixLine.getRCAddress(lineAddress);
+    while (line < LINES_IN_BLOCK) {
+      byte value = lineRCAddress.loadByte();
+      if (value >= RCImmixObjectHeader.LIVE_THRESHOLD) break;
+      line++;
+      lineRCAddress = lineRCAddress.plus(BYTES_IN_LINE_RC_ENTRY);
+    }
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(line >= 0 && line <= LINES_IN_BLOCK);
+    return line;
+  }
+
+  @Inline
+  public static int getNextAvailable(Address blockAddress, int line) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(line >= 0 && line < LINES_IN_BLOCK);
+    Address lineAddress = blockAddress.plus(Extent.fromIntZeroExtend(line<<LOG_BYTES_IN_LINE));
+    lineAddress = RCImmixLine.align(lineAddress);
+    Address lineRCAddress = RCImmixLine.getRCAddress(lineAddress);
+    byte last = lineRCAddress.loadByte();
+    byte thisline;
+    line++;
+    lineRCAddress = lineRCAddress.plus(BYTES_IN_LINE_RC_ENTRY);
+    while (line < LINES_IN_BLOCK) {
+      thisline = lineRCAddress.loadByte();
+      if (thisline < RCImmixObjectHeader.LIVE_THRESHOLD && last < RCImmixObjectHeader.LIVE_THRESHOLD) break;
+      last = thisline;
+      line++;
+      lineRCAddress = lineRCAddress.plus(BYTES_IN_LINE_RC_ENTRY);
+    }
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(line >= 0 && line <= LINES_IN_BLOCK);
+    return line;
+  }
+
+  private static Address getMetaAddressRC(Address address, final int tableOffset) {
+    Address chunk = RCImmixChunk.align(address);
+    int index = getChunkIndex(address);
+    Address rtn = chunk.plus(tableOffset + (index<<LOG_BYTES_IN_LINE_RC_ENTRY));
+    if (VM.VERIFY_ASSERTIONS) {
+      Address line = chunk.plus(index<<LOG_BYTES_IN_LINE);
+      VM.assertions._assert(isAligned(line));
+      VM.assertions._assert(align(address).EQ(line));
+      boolean valid = rtn.GE(chunk.plus(tableOffset)) && rtn.LT(chunk.plus(tableOffset + LINE_RC_TABLE_BYTES));
+      VM.assertions._assert(valid);
+    }
+    return rtn;
+  }
+
+  public static Address getRCAddress(Address address) {
+    return getMetaAddressRC(address, RCImmixChunk.LINE_RC_TABLE_OFFSET);
+  }
+
+
+  /* per-line rc bytes */
+  public static final int LOG_BYTES_IN_LINE_RC_ENTRY = 0;
+  static final int BYTES_IN_LINE_RC_ENTRY = 1<<LOG_BYTES_IN_LINE_RC_ENTRY;
+  static final int LINE_RC_TABLE_BYTES = LINES_IN_CHUNK<<LOG_BYTES_IN_LINE_RC_ENTRY;
+  static final int LOG_LINE_RC_BYTES_PER_BLOCK = LOG_LINES_IN_BLOCK+LOG_BYTES_IN_LINE_RC_ENTRY;
+  public static final int LINE_RC_BYTES_PER_BLOCK = (1<<LOG_LINE_RC_BYTES_PER_BLOCK);
+
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/policy/rcimmix/RCImmixMutatorLocal.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/policy/rcimmix/RCImmixMutatorLocal.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,53 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.policy.rcimmix;
+
+import org.mmtk.utility.alloc.RCImmixAllocator;
+
+import org.vmmagic.pragma.*;
+
+/**
+ *
+ */
+@Uninterruptible
+public final class RCImmixMutatorLocal extends RCImmixAllocator {
+  /**
+   * Constructor
+   *
+   * @param space The mark-sweep space to which this allocator
+   * instances is bound.
+   * @param hot TODO
+   */
+  public RCImmixMutatorLocal(RCImmixSpace space, boolean hot) {
+    super(space, hot, false);
+  }
+
+  /****************************************************************************
+   *
+   * Collection
+   */
+
+  /**
+   * Prepare for a collection. If paranoid, perform a sanity check.
+   */
+  public void prepare() {
+    reset();
+  }
+
+  /**
+   * Finish up after a collection.
+   */
+  public void release() {
+    reset();
+  }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/policy/rcimmix/RCImmixObjectHeader.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/policy/rcimmix/RCImmixObjectHeader.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,603 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.policy.rcimmix;
+
+import static org.mmtk.utility.Constants.BITS_IN_BYTE;
+import static org.mmtk.utility.Constants.BITS_IN_ADDRESS;
+
+import org.mmtk.utility.ForwardingWord;
+import org.mmtk.vm.VM;
+import org.vmmagic.pragma.Inline;
+import org.vmmagic.pragma.Uninterruptible;
+import org.vmmagic.unboxed.Address;
+import org.vmmagic.unboxed.ObjectReference;
+import org.vmmagic.unboxed.Word;
+
+@Uninterruptible
+public class RCImmixObjectHeader {
+
+  public static boolean performCycleCollection = false;
+  public static boolean performSurvivorCopy = false;
+  public static final byte LINE_INCREMENT = 2;
+  public static final byte LIVE_THRESHOLD = 2;
+  public static final byte LINE_MARK_BIT_MASK = 1;
+  public static final byte ZERO = 0;
+  public static final byte ONE = 1;
+  public static final byte LINE_INCREMENT_MARK = 3;
+
+   /****************************************************************************
+   * Object Logging (applies to *all* objects)
+   */
+
+  /* Mask bits to signify the start/finish of logging an object */
+  public static final int      LOG_BIT  = 0;
+  public static final Word     LOGGED = Word.zero();                            //...00000
+  public static final Word     UNLOGGED   = Word.one();                         //...00001
+  public static final Word BEING_LOGGED = Word.one().lsh(2).minus(Word.one());  //...00011
+  public static final Word LOGGING_MASK = LOGGED.or(UNLOGGED).or(BEING_LOGGED); //...00011
+
+  /**
+   * Return true if <code>object</code> is yet to be logged (for
+   * coalescing RC).
+   *
+   * @param object The object in question
+   * @return <code>true</code> if <code>object</code> needs to be logged.
+   */
+  @Inline
+  @Uninterruptible
+  public static boolean logRequired(ObjectReference object) {
+    Word value = VM.objectModel.readAvailableBitsWord(object);
+    return value.and(LOGGING_MASK).EQ(UNLOGGED);
+  }
+
+  /**
+   * Attempt to log <code>object</code> for coalescing RC. This is
+   * used to handle a race to log the object, and returns
+   * <code>true</code> if we are to log the object and
+   * <code>false</code> if we lost the race to log the object.
+   *
+   * <p>If this method returns <code>true</code>, it leaves the object
+   * in the <code>BEING_LOGGED</code> state.  It is the responsibility
+   * of the caller to change the object to <code>LOGGED</code> once
+   * the logging is complete.
+   *
+   * @see #makeLogged(ObjectReference)
+   * @param object The object in question
+   * @return <code>true</code> if the race to log
+   * <code>object</code>was won.
+   */
+  @Inline
+  @Uninterruptible
+  public static boolean attemptToLog(ObjectReference object) {
+    Word oldValue;
+    do {
+      oldValue = VM.objectModel.prepareAvailableBits(object);
+      if (oldValue.and(LOGGING_MASK).EQ(LOGGED)) {
+        return false;
+      }
+    } while ((oldValue.and(LOGGING_MASK).EQ(BEING_LOGGED)) ||
+             !VM.objectModel.attemptAvailableBits(object, oldValue, oldValue.or(BEING_LOGGED)));
+    if (VM.VERIFY_ASSERTIONS) {
+      Word value = VM.objectModel.readAvailableBitsWord(object);
+      VM.assertions._assert(value.and(LOGGING_MASK).EQ(BEING_LOGGED));
+    }
+    return true;
+  }
+
+
+  /**
+   * Signify completion of logging <code>object</code>.
+   *
+   * <code>object</code> is left in the <code>LOGGED</code> state.
+   *
+   * @see #attemptToLog(ObjectReference)
+   * @param object The object whose state is to be changed.
+   */
+  @Inline
+  @Uninterruptible
+  public static void makeLogged(ObjectReference object) {
+    Word value = VM.objectModel.readAvailableBitsWord(object);
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(value.and(LOGGING_MASK).NE(LOGGED));
+    VM.objectModel.writeAvailableBitsWord(object, value.and(LOGGING_MASK.not()));
+  }
+
+  /**
+   * Change <code>object</code>'s state to <code>UNLOGGED</code>.
+   *
+   * @param object The object whose state is to be changed.
+   */
+  @Inline
+  @Uninterruptible
+  public static void makeUnlogged(ObjectReference object) {
+    Word oldValue, newValue;
+    do {
+      oldValue = VM.objectModel.prepareAvailableBits(object);
+      newValue = oldValue.or(UNLOGGED);
+      newValue = newValue.and(MARK_BIT_MASK.not()).or(markAllocValue);
+    } while (!VM.objectModel.attemptAvailableBits(object, oldValue, newValue));
+  }
+
+  /************************************************************************
+   * RC header word
+   */
+  /* The bit used for newly allocated objects */
+  public static final int NEW_BIT = LOG_BIT + 2;
+  public static final Word NEW_BIT_MASK = Word.one().lsh(NEW_BIT);
+
+  /* The mark bit used for backup tracing. */
+  public static final int MARK_BIT = NEW_BIT + 1;
+  public static final Word MARK_BIT_MASK = Word.one().lsh(MARK_BIT);
+
+  public static final int STRADDLE_BIT = MARK_BIT + 1;
+  public static final Word STRADDLE_BIT_MASK = Word.one().lsh(STRADDLE_BIT);
+
+  public static final int PIN_BIT = VM.config.PINNING_BIT ? (STRADDLE_BIT + 1) : STRADDLE_BIT;
+  public static final Word PIN_BIT_MASK = Word.one().lsh(PIN_BIT);
+
+  /* Current not using any bits for cycle detection, etc */
+  public static final int BITS_USED = PIN_BIT + 1;
+
+  public static Word markValue = MARK_BIT_MASK;
+  public static Word markAllocValue = Word.zero();
+
+  /* Reference counting increments */
+  public static final int INCREMENT_SHIFT = BITS_USED;
+  public static final Word INCREMENT = Word.one().lsh(INCREMENT_SHIFT);
+  public static final int AVAILABLE_BITS = BITS_IN_ADDRESS - BITS_USED;
+  public static final Word OBJECT_LIVE_THRESHOLD = INCREMENT;
+
+  public static final Word refSticky = Word.one().lsh(BITS_IN_BYTE - BITS_USED).minus(Word.one()).lsh(INCREMENT_SHIFT);
+  public static final int refStickyValue = refSticky.rshl(INCREMENT_SHIFT).toInt();
+  public static final Word WRITE_MASK = refSticky.not();
+  public static final Word READ_MASK = refSticky;
+
+  /* Return values from decRC */
+  public static final int DEC_KILL = 0;
+  public static final int DEC_ALIVE = 1;
+
+  /* Return values from incRC */
+  public static final int INC_OLD = 0;
+  public static final int INC_NEW = 1;
+
+  /**
+   * Has this object been marked by the most recent backup trace.
+   */
+  @Inline
+  public static boolean isMarked(ObjectReference object) {
+    return isHeaderMarked(VM.objectModel.readAvailableBitsWord(object));
+  }
+
+  @Inline
+  public static boolean isMarked(ObjectReference object, Word headerWord) {
+    return isHeaderMarked(headerWord);
+  }
+
+  /**
+   * Has this object been marked by the most recent backup trace.
+   */
+  @Inline
+  public static void clearMarked(ObjectReference object) {
+    Word oldValue, newValue;
+    do {
+      oldValue = VM.objectModel.prepareAvailableBits(object);
+      if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(isHeaderMarked(oldValue));
+      newValue = oldValue.xor(MARK_BIT_MASK);
+    } while (!VM.objectModel.attemptAvailableBits(object, oldValue, newValue));
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!isHeaderMarked(newValue));
+  }
+
+
+  /**
+   * Has this object been marked by the most recent backup trace.
+   */
+  @Inline
+  private static boolean isHeaderMarked(Word header) {
+    return header.and(MARK_BIT_MASK).EQ(markValue);
+  }
+
+  @Inline
+  public static boolean isMarked(byte header) {
+    return (header & MARK_BIT_MASK.toInt()) == markValue.toInt();
+  }
+
+  @Inline
+  public static void setMarkStateAndUnlock(ObjectReference object, byte status) {
+    byte oldValue = status;
+    byte newValue = (byte) (oldValue & ~ForwardingWord.FORWARDING_MASK);
+    newValue = (byte) (newValue | ForwardingWord.CLEAR_FORWARDING);
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!isMarked(oldValue));
+    newValue = (byte) (newValue ^ MARK_BIT_MASK.toInt());
+    VM.objectModel.writeAvailableByte(object, newValue);
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(isMarked(newValue));
+  }
+
+  @Inline
+  public static void returnToPriorState(ObjectReference object, byte status) {
+    VM.objectModel.writeAvailableByte(object, status);
+  }
+
+  /**
+   * Attempt to atomically mark this object. Return true if the mark was performed.
+   */
+  @Inline
+  public static boolean testAndMark(ObjectReference object) {
+    Word oldValue, newValue;
+    do {
+      oldValue = VM.objectModel.prepareAvailableBits(object);
+      if (isHeaderMarked(oldValue)) {
+        return false;
+      }
+      newValue = oldValue.xor(MARK_BIT_MASK);
+    } while (!VM.objectModel.attemptAvailableBits(object, oldValue, newValue));
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(isHeaderMarked(newValue));
+    return true;
+  }
+
+  @Inline
+  public static void writeMarkState(ObjectReference object, boolean straddling) {
+    byte oldValue = VM.objectModel.readAvailableByte(object);
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!isMarked(oldValue));
+    byte newValue = (byte) (oldValue & ~ForwardingWord.FORWARDING_MASK);
+    newValue = (byte) (newValue | ForwardingWord.CLEAR_FORWARDING);
+    newValue = (byte) (newValue ^ MARK_BIT_MASK.toInt());
+    if (straddling) newValue = (byte) (newValue | STRADDLE_BIT_MASK.toInt());
+    VM.objectModel.writeAvailableByte(object, newValue);
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(isMarked(newValue));
+  }
+
+  /**
+   * Has this object been marked by the most recent backup trace.
+   */
+  @Inline
+  public static void markAsStraddling(ObjectReference object) {
+    Word oldValue, newValue;
+    do {
+      oldValue = VM.objectModel.prepareAvailableBits(object);
+      newValue = oldValue.or(STRADDLE_BIT_MASK);
+    } while (!VM.objectModel.attemptAvailableBits(object, oldValue, newValue));
+  }
+
+  /**
+   * Has this object been marked as new
+   */
+  @Inline
+  private static boolean isHeaderStraddle(Word header) {
+    return header.and(STRADDLE_BIT_MASK).EQ(STRADDLE_BIT_MASK);
+  }
+
+  /**
+   * Has this object been marked as new
+   */
+  @Inline
+  public static boolean isStraddlingObject(ObjectReference object) {
+    return isHeaderStraddle(VM.objectModel.readAvailableBitsWord(object));
+  }
+
+  /**
+   * Has this object been marked as new
+   */
+  @Inline
+  public static boolean isHeaderNew(Word header) {
+    return header.and(NEW_BIT_MASK).NE(NEW_BIT_MASK);
+  }
+
+  /**
+   * Has this object been marked as new
+   */
+  @Inline
+  public static boolean isNew(ObjectReference object) {
+    return isHeaderNew(VM.objectModel.readAvailableBitsWord(object));
+  }
+
+  @Inline
+  public static void clearNew(ObjectReference object) {
+    Word oldValue, newValue;
+    do {
+      oldValue = VM.objectModel.prepareAvailableBits(object);
+      newValue = oldValue.or(NEW_BIT_MASK);
+    } while (!VM.objectModel.attemptAvailableBits(object, oldValue, newValue));
+  }
+
+
+  /**
+   * Perform any required initialization of the GC portion of the header.
+   *
+   * @param object the object
+   * @param initialInc start with a reference count of 1 (0 if false)
+   */
+  @Inline
+  public static void initializeHeader(ObjectReference object, boolean initialInc, int bytes) {
+    Word oldValue = VM.objectModel.readAvailableBitsWord(object);
+    Word initialValue =  (initialInc) ? INCREMENT : Word.zero();
+    VM.objectModel.writeAvailableBitsWord(object, oldValue.or(initialValue));
+  }
+
+  @Inline
+  public static void initializeHeader(ObjectReference object) {
+    Word oldValue = VM.objectModel.readAvailableBitsWord(object);
+    VM.objectModel.writeAvailableBitsWord(object, oldValue.or(STRADDLE_BIT_MASK));
+  }
+
+  @Inline
+  public static void initializeHeaderOther(ObjectReference object, boolean initialInc) {
+    Word oldValue = VM.objectModel.readAvailableBitsWord(object);
+    Word initialValue =  (initialInc) ? INCREMENT : Word.zero();
+    VM.objectModel.writeAvailableBitsWord(object, oldValue.or(initialValue));
+  }
+
+  /**
+   * Return true if given object is live
+   *
+   * @param object The object whose liveness is to be tested
+   * @return True if the object is alive
+   */
+  @Inline
+  @Uninterruptible
+  public static boolean isLiveRC(ObjectReference object) {
+    Word value = VM.objectModel.readAvailableBitsWord(object);
+    if (isStuck(value)) return true;
+    return value.and(READ_MASK).GE(OBJECT_LIVE_THRESHOLD);
+  }
+
+  /**
+   * Return the reference count for the object.
+   *
+   * @param object The object whose liveness is to be tested
+   * @return True if the object is alive
+   */
+  @Inline
+  @Uninterruptible
+  public static int getRC(ObjectReference object) {
+    Word value = VM.objectModel.readAvailableBitsWord(object);
+    if (isStuck(value)) return refStickyValue;
+    return value.and(READ_MASK).rshl(INCREMENT_SHIFT).toInt();
+  }
+
+  /**
+   * Increment the reference count of an object.
+   *
+   * @param object The object whose reference count is to be incremented.
+   */
+  @Inline
+  public static int incRC(ObjectReference object) {
+    Word oldValue, newValue;
+    int rtn;
+    do {
+      oldValue = VM.objectModel.prepareAvailableBits(object);
+      if (isStuck(oldValue)) return INC_OLD;
+      if (isHeaderNew(oldValue)) {
+        newValue = oldValue.plus(INCREMENT);
+        newValue = newValue.or(NEW_BIT_MASK);
+        rtn = INC_NEW;
+      } else {
+        newValue = oldValue.plus(INCREMENT);
+        rtn = INC_OLD;
+      }
+    } while (!VM.objectModel.attemptAvailableBits(object, oldValue, newValue));
+    return rtn;
+  }
+
+  /**
+   * Decrement the reference count of an object.  Return either
+   * <code>DEC_KILL</code> if the count went to zero,
+   * <code>DEC_ALIVE</code> if the count did not go to zero.
+   *
+   * @param object The object whose RC is to be decremented.
+   * @return <code>DEC_KILL</code> if the count went to zero,
+   * <code>DEC_ALIVE</code> if the count did not go to zero.
+   */
+  @Inline
+  @Uninterruptible
+  public static int decRC(ObjectReference object) {
+    Word oldValue, newValue;
+    int rtn;
+    do {
+      oldValue = VM.objectModel.prepareAvailableBits(object);
+      if (isStuck(oldValue)) return DEC_ALIVE;
+      newValue = oldValue.minus(INCREMENT);
+      if (newValue.and(READ_MASK).LT(OBJECT_LIVE_THRESHOLD)) {
+        rtn = DEC_KILL;
+      } else {
+        rtn = DEC_ALIVE;
+      }
+    } while (!VM.objectModel.attemptAvailableBits(object, oldValue, newValue));
+    return rtn;
+  }
+
+  /**
+   * Initialize the reference count of an object.
+   *
+   * @param object The object whose reference count is to be initialized.
+   */
+  @Inline
+  public static int initRC(ObjectReference object) {
+    Word oldValue, newValue;
+    int rtn;
+    do {
+      oldValue = VM.objectModel.prepareAvailableBits(object);
+      newValue = oldValue.and(WRITE_MASK).or(INCREMENT);
+      if (isHeaderNew(oldValue)) {
+        newValue=newValue.or(NEW_BIT_MASK);
+        rtn = INC_NEW;
+      } else {
+        rtn = INC_OLD;
+      }
+    } while (!VM.objectModel.attemptAvailableBits(object, oldValue, newValue));
+    return rtn;
+  }
+
+  /**
+   * Initialize the reference count of an object.
+   *
+   * @param object The object whose reference count is to be initialized.
+   */
+  @Inline
+  public static int remainRC(ObjectReference object) {
+    Word oldValue, newValue;
+    int rtn;
+    do {
+      oldValue = VM.objectModel.prepareAvailableBits(object);
+      newValue = oldValue;
+      if (isHeaderNew(oldValue)) {
+        newValue=newValue.or(NEW_BIT_MASK);
+        rtn = INC_NEW;
+      } else {
+        return INC_OLD;
+      }
+    } while (!VM.objectModel.attemptAvailableBits(object, oldValue, newValue));
+    return rtn;
+  }
+
+  @Inline
+  private static boolean isStuck(Word value) {
+    return value.and(refSticky).EQ(refSticky);
+  }
+
+  @Inline
+  private static void incLineRC(Address address) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!RCImmixBlock.isUnused(RCImmixBlock.align(address)));
+    address = RCImmixLine.align(address);
+    Address line = RCImmixLine.getRCAddress(address);
+    byte oldValue = line.loadByte();
+    byte newValue = (byte)(oldValue + LINE_INCREMENT);
+    line.store(newValue);
+  }
+
+  @Inline
+  private static void incMultiLineRC(Address start, ObjectReference object) {
+    Address endLine = RCImmixLine.align(VM.objectModel.getObjectEndAddress(object).minus(1));
+    Address line = RCImmixLine.align(start.plus(RCImmixConstants.BYTES_IN_LINE));
+    while (line.LT(endLine)) {
+      if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(RCImmixBlock.align(start).EQ(RCImmixBlock.align(line)));
+      incLineRC(line);
+      line = line.plus(RCImmixConstants.BYTES_IN_LINE);
+    }
+  }
+
+  @Inline
+  private static void decLineRC(Address address) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!RCImmixBlock.isUnused(RCImmixBlock.align(address)));
+    address = RCImmixLine.align(address);
+    Address line = RCImmixLine.getRCAddress(address);
+    byte oldValue = line.loadByte();
+    byte newValue = (byte) (oldValue - LINE_INCREMENT);
+    line.store(newValue);
+  }
+
+  @Inline
+  private static void decMultiLineRC(Address start, ObjectReference object) {
+    Address endLine = RCImmixLine.align(VM.objectModel.getObjectEndAddress(object).minus(1));
+    Address line = RCImmixLine.align(start.plus(RCImmixConstants.BYTES_IN_LINE));
+    while (line.LT(endLine)) {
+      if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(RCImmixBlock.align(start).EQ(RCImmixBlock.align(line)));
+      decLineRC(line);
+      line = line.plus(RCImmixConstants.BYTES_IN_LINE);
+    }
+  }
+
+  @Inline
+  private static boolean testAndMarkLine(Address address) {
+    address = RCImmixLine.align(address);
+    Address line = RCImmixLine.getRCAddress(address);
+    byte oldValue = line.loadByte();
+    byte newValue;
+    if ((oldValue & LINE_MARK_BIT_MASK) == LINE_MARK_BIT_MASK) {
+      newValue = (byte) (oldValue + LINE_INCREMENT);
+    } else {
+      newValue = LINE_INCREMENT_MARK;
+    }
+    line.store(newValue);
+    return true;
+  }
+
+  @Inline
+  private static void testAndMarkMultiLine(Address start, ObjectReference object) {
+    Address endLine = RCImmixLine.align(VM.objectModel.getObjectEndAddress(object).minus(1));
+    Address line = RCImmixLine.align(start.plus(RCImmixConstants.BYTES_IN_LINE));
+    while (line.LT(endLine)) {
+      if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(RCImmixBlock.align(start).EQ(RCImmixBlock.align(line)));
+      testAndMarkLine(line);
+      line = line.plus(RCImmixConstants.BYTES_IN_LINE);
+    }
+  }
+
+  @Inline
+  public static void incLines(ObjectReference object) {
+    Address address = VM.objectModel.objectStartRef(object);
+    incLineRC(address);
+    if (isStraddlingObject(object)) {
+      incMultiLineRC(address, object);
+    }
+  }
+
+  @Inline
+  public static void decLines(ObjectReference object) {
+    Address address = VM.objectModel.objectStartRef(object);
+    decLineRC(address);
+    if (isStraddlingObject(object)) {
+      decMultiLineRC(address, object);
+    }
+  }
+
+  @Inline
+  public static void testAndMarkLines(ObjectReference object) {
+    Address address = VM.objectModel.objectStartRef(object);
+    testAndMarkLine(address);
+    if (isStraddlingObject(object)) {
+      testAndMarkMultiLine(address, object);
+    }
+  }
+
+  @Inline
+  public static void pinObject(ObjectReference object) {
+    if (!VM.config.PINNING_BIT) return;
+    Word oldValue, newValue;
+    do {
+      oldValue = VM.objectModel.prepareAvailableBits(object);
+      newValue = oldValue.or(PIN_BIT_MASK);
+    } while (!VM.objectModel.attemptAvailableBits(object, oldValue, newValue));
+  }
+
+  @Inline
+  public static boolean isPinnedObject(ObjectReference object) {
+    if (!VM.config.PINNING_BIT) return false;
+    Word value = VM.objectModel.readAvailableBitsWord(object);
+    return value.and(PIN_BIT_MASK).EQ(PIN_BIT_MASK);
+  }
+
+  @Inline
+  public static void writeStateYoungObject(ObjectReference object, boolean straddling) {
+    byte oldValue = VM.objectModel.readAvailableByte(object);
+    byte newValue = (byte) (oldValue & ~ForwardingWord.FORWARDING_MASK);
+    if (straddling) newValue = (byte) (newValue | STRADDLE_BIT_MASK.toInt());
+    newValue = (byte) (newValue | NEW_BIT_MASK.toInt());
+    VM.objectModel.writeAvailableByte(object, newValue);
+  }
+
+  @Inline
+  public static void clearStateYoungObject(ObjectReference object) {
+    byte oldValue = VM.objectModel.readAvailableByte(object);
+    byte newValue = (byte) (oldValue & ~ForwardingWord.FORWARDING_MASK);
+    VM.objectModel.writeAvailableByte(object, newValue);
+  }
+
+  @Inline
+  public static void incRCOld(ObjectReference object) {
+    Word oldValue, newValue;
+    do {
+      oldValue = VM.objectModel.prepareAvailableBits(object);
+      if (isStuck(oldValue)) return;
+      newValue = oldValue.plus(INCREMENT);
+    } while (!VM.objectModel.attemptAvailableBits(object, oldValue, newValue));
+  }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/policy/rcimmix/RCImmixSpace.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/policy/rcimmix/RCImmixSpace.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,746 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.policy.rcimmix;
+
+import static org.mmtk.policy.rcimmix.RCImmixConstants.*;
+import static org.mmtk.utility.Constants.LOG_BYTES_IN_PAGE;
+
+import org.mmtk.plan.TransitiveClosure;
+import org.mmtk.policy.Space;
+import org.mmtk.utility.heap.*;
+import org.mmtk.utility.options.LineReuseRatio;
+import org.mmtk.utility.options.Options;
+import org.mmtk.utility.ForwardingWord;
+import org.mmtk.utility.HeaderByte;
+import org.mmtk.utility.Log;
+import org.mmtk.vm.Lock;
+import org.mmtk.vm.VM;
+import org.vmmagic.pragma.*;
+import org.vmmagic.unboxed.*;
+
+/**
+ * Each instance of this class corresponds to one immix <b>space</b>.
+ * Each of the instance methods of this class may be called by any
+ * thread (i.e. synchronization must be explicit in any instance or
+ * class method).  This contrasts with the SquishLocal, where
+ * instances correspond to *plan* instances and therefore to kernel
+ * threads.  Thus unlike this class, synchronization is not necessary
+ * in the instance methods of SquishLocal.
+ *
+ */
+@Uninterruptible
+public final class RCImmixSpace extends Space {
+
+  /****************************************************************************
+   *
+   * Class variables
+   */
+
+  /**
+   *
+   */
+  private static short reusableMarkStateThreshold = 0;
+
+  /****************************************************************************
+   *
+   * Instance variables
+   */
+
+  /**
+   *
+   */
+  private boolean inCollection;
+  private int linesConsumed = 0;
+
+  private Lock mutatorLock = VM.newLock(getName()+"mutator");
+  private Lock gcLock = VM.newLock(getName()+"gc");
+
+  private Address allocBlockCursor = Address.zero();
+  private Address allocBlockSentinel = Address.zero();
+  private boolean exhaustedReusableSpace = true;
+  public boolean exhaustedCopySpace = false;
+  public int maxCleanPagesForCopy = 0;
+  public double linesUsed = 0;
+  public double linesCleaned = 0;
+
+
+  private final RCImmixChunkList chunkMap = new RCImmixChunkList();
+  private final RCImmixDefrag rCImmixDefrag;
+
+  /****************************************************************************
+   *
+   * Initialization
+   */
+
+  static {
+    Options.lineReuseRatio = new LineReuseRatio();
+    reusableMarkStateThreshold = (short) (Options.lineReuseRatio.getValue() * MAX_BLOCK_MARK_STATE);
+  }
+
+  /**
+   * The caller specifies the region of virtual memory to be used for
+   * this space.  If this region conflicts with an existing space,
+   * then the constructor will fail.
+   *
+   * @param name The name of this space (used when printing error messages etc)
+   * @param vmRequest The virtual memory request
+   */
+  public RCImmixSpace(String name, VMRequest vmRequest) {
+    this(name, true, vmRequest);
+  }
+
+  /**
+   * The caller specifies the region of virtual memory to be used for
+   * this space.  If this region conflicts with an existing space,
+   * then the constructor will fail.
+   *
+   * @param name The name of this space (used when printing error messages etc)
+   * @param zeroed if true, allocations return zeroed memory
+   * @param vmRequest The virtual memory request
+   */
+  public RCImmixSpace(String name, boolean zeroed, VMRequest vmRequest) {
+    super(name, false, false, zeroed, vmRequest);
+    if (vmRequest.isDiscontiguous())
+      pr = new FreeListPageResource(this, RCImmixChunk.getRequiredMetaDataPages());
+    else
+      pr = new FreeListPageResource(this, start, extent, RCImmixChunk.getRequiredMetaDataPages());
+    rCImmixDefrag = new RCImmixDefrag((FreeListPageResource) pr);
+  }
+
+  /****************************************************************************
+   *
+   * Global prepare and release
+   */
+
+  /**
+   * Prepare for a new collection increment.
+   */
+  public void prepare(boolean majorGC) {
+    chunkMap.reset();
+    rCImmixDefrag.prepare(chunkMap, this);
+    inCollection = true;
+
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(VM.activePlan.collectorCount() <= MAX_COLLECTORS);
+  }
+
+  /**
+   * A new collection increment has completed.  Release global resources.
+   * @param majorGC TODO
+   */
+  public boolean release(boolean majorGC) {
+    boolean didDefrag = rCImmixDefrag.inDefrag();
+    chunkMap.reset();
+    rCImmixDefrag.globalRelease();
+    inCollection = false;
+
+    /* set up reusable space */
+    if (allocBlockCursor.isZero()) allocBlockCursor = chunkMap.getHeadChunk();
+    allocBlockSentinel = allocBlockCursor;
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(isRecycleAllocChunkAligned(allocBlockSentinel));
+    exhaustedReusableSpace = allocBlockCursor.isZero();
+    if (VM.VERIFY_ASSERTIONS && Options.verbose.getValue() >= 9) {
+      Log.write("gr[allocBlockCursor: "); Log.write(allocBlockCursor); Log.write(" allocBlockSentinel: "); Log.write(allocBlockSentinel); Log.writeln("]");
+    }
+
+    /* really just want this to happen once after options are booted, but no harm in re-doing it */
+    reusableMarkStateThreshold = (short) (Options.lineReuseRatio.getValue() * MAX_BLOCK_MARK_STATE);
+    RCImmixDefrag.defragReusableMarkStateThreshold = (short) (Options.defragLineReuseRatio.getValue() * MAX_BLOCK_MARK_STATE);
+
+    linesConsumed = 0;
+    return didDefrag;
+  }
+
+  /**
+   * Determine the collection kind.
+   *
+   * @param emergencyCollection Is this collection an emergency (last did not yield enough)?
+   * @param collectWholeHeap Is this a whole heap collection?
+   * @param collectionAttempt Which attempt is this to collect?
+   * @param userTriggeredCollection Was this collection requested by the user?
+   */
+  public void decideWhetherToDefrag(boolean emergencyCollection, boolean collectWholeHeap, int collectionAttempt, boolean userTriggeredCollection, boolean forceDefrag) {
+    rCImmixDefrag.decideWhetherToDefrag(emergencyCollection, collectWholeHeap, collectionAttempt, userTriggeredCollection, exhaustedReusableSpace, forceDefrag);
+  }
+
+  /**
+   * Return the amount of headroom required to allow defrag, so this can be included in a collection reserve.
+   *
+   * @return The number of pages.
+   */
+  public int defragHeadroomPages() {
+    return rCImmixDefrag.getDefragHeadroomPages();
+  }
+
+ /****************************************************************************
+  *
+  * Collection state access methods
+  */
+
+  /**
+   * Return {@code true} if this space is currently being collected.
+   *
+   * @return {@code true} if this space is currently being collected.
+   */
+  @Inline
+  public boolean inImmixCollection() {
+    return inCollection;
+  }
+
+  /**
+   * Return {@code true} if this space is currently being defraged.
+   *
+   * @return {@code true} if this space is currently being defraged.
+   */
+  @Inline
+  public boolean inImmixDefragCollection() {
+    return inCollection && rCImmixDefrag.inDefrag();
+  }
+
+  /**
+   * Return the number of pages allocated since the last collection
+   *
+   * @return The number of pages allocated since the last collection
+   */
+  public int getPagesAllocated() {
+    return linesConsumed>>(LOG_BYTES_IN_PAGE-LOG_BYTES_IN_LINE);
+  }
+
+  /**
+   * Return the reusable mark state threshold, which determines how
+   * eagerly lines should be recycled (by default these values are
+   * set so that all lines are recycled).
+   *
+   * @param forDefrag The query is the context of a defragmenting collection
+   * @return The reusable mark state threshold
+   */
+  @Inline
+  public static short getReusuableMarkStateThreshold(boolean forDefrag) {
+    return forDefrag ? RCImmixDefrag.defragReusableMarkStateThreshold : reusableMarkStateThreshold;
+  }
+
+  /****************************************************************************
+   *
+   * Allocation
+   */
+
+  /**
+   * Return a pointer to a set of new usable blocks, or null if none are available.
+   * Use different block selection heuristics depending on whether the allocation
+   * request is "hot" or "cold".
+   *
+   * @param hot True if the requesting context is for hot allocations (used for
+   * allocations from high allocation volume sites).
+   * @return The pointer into the alloc table containing usable blocks.
+   */
+  public Address getSpace(boolean hot, boolean copy, int lineUseCount) {
+    Address rtn;
+    if (copy)
+      rCImmixDefrag.getBlock();
+
+    if (!VM.activePlan.isMutator() && RCImmixObjectHeader.performSurvivorCopy) {
+      if ((maxCleanPagesForCopy - PAGES_IN_BLOCK) >= 0) {
+        maxCleanPagesForCopy-= PAGES_IN_BLOCK;
+      } else {
+        exhaustedCopySpace = true; // this flag is used to control survivor copy
+      }
+    }
+
+    linesConsumed += lineUseCount;
+
+    rtn = acquire(PAGES_IN_BLOCK);
+    if (VM.activePlan.isMutator()) {
+      linesUsed += LINES_IN_BLOCK;
+    }
+
+
+    if (VM.VERIFY_ASSERTIONS) {
+      VM.assertions._assert(RCImmixBlock.isAligned(rtn));
+      VM.assertions._assert(!(copy && RCImmixBlock.isDefragSource(rtn)));
+    }
+
+    if (!rtn.isZero()) {
+      RCImmixBlock.setBlockAsInUse(rtn);
+      RCImmixChunk.updateHighWater(rtn);
+      if (VM.VERIFY_ASSERTIONS && Options.verbose.getValue() >= 9) {
+        Log.write("gs["); Log.write(rtn); Log.write(" -> "); Log.write(rtn.plus(BYTES_IN_BLOCK-1)); Log.write(" copy: "); Log.write(copy); Log.writeln("]");
+      }
+    }
+
+    return rtn;
+  }
+
+  @Override
+  public void growSpace(Address start, Extent bytes, boolean newChunk) {
+    super.growSpace(start, bytes, newChunk);
+     if (newChunk) {
+      Address chunk = chunkAlign(start.plus(bytes), true);
+      if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(chunkAlign(start.plus(bytes), true).EQ(chunk));
+      RCImmixChunk.clearMetaData(chunk);
+      chunkMap.addNewChunkToMap(chunk);
+    }
+  }
+
+  public Address acquireReusableBlocks() {
+    if (VM.VERIFY_ASSERTIONS) {
+      VM.assertions._assert(isRecycleAllocChunkAligned(allocBlockCursor));
+      VM.assertions._assert(isRecycleAllocChunkAligned(allocBlockSentinel));
+    }
+    Address rtn;
+
+    lock();
+    if (exhaustedReusableSpace)
+      rtn = Address.zero();
+    else {
+      rtn = allocBlockCursor;
+      Address lastAllocChunk = chunkAlign(allocBlockCursor, true);
+      allocBlockCursor = allocBlockCursor.plus(BYTES_IN_RECYCLE_ALLOC_CHUNK);
+      if (allocBlockCursor.GT(RCImmixChunk.getHighWater(lastAllocChunk)))
+        allocBlockCursor = chunkMap.nextChunk(lastAllocChunk);
+      if (VM.VERIFY_ASSERTIONS && Options.verbose.getValue() >= 9) {
+        Log.write("arb[ rtn: "); Log.write(rtn); Log.write(" allocBlockCursor: "); Log.write(allocBlockCursor); Log.write(" allocBlockSentinel: "); Log.write(allocBlockSentinel); Log.writeln("]");
+      }
+
+      if (allocBlockCursor.isZero() || allocBlockCursor.EQ(allocBlockSentinel)) {
+        exhaustedReusableSpace = true;
+        if (VM.VERIFY_ASSERTIONS && Options.verbose.getValue() >= 9) {
+          Log.writeln("[Reusable space exhausted]");
+        }
+      }
+    }
+    unlock();
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(isRecycleAllocChunkAligned(rtn));
+    return rtn;
+  }
+
+  /**
+   * Release a block.  A block is free, so call the underlying page allocator
+   * to release the associated storage.
+   *
+   * @param block The address of the block to be released
+   */
+  @Override
+  @Inline
+  public void release(Address block) {
+    if (RCImmixBlock.getRCAddress(block).loadByte() == RCImmixObjectHeader.ONE) {
+      RCImmixBlock.getRCAddress(block).store(RCImmixObjectHeader.ZERO);
+    } else {
+      linesCleaned += LINES_IN_BLOCK;
+    }
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(RCImmixBlock.isAligned(block));
+    RCImmixBlock.setBlockAsUnallocated(block);
+    ((FreeListPageResource) pr).releasePages(block);
+  }
+
+  /**
+   * {@inheritDoc}<p>
+   *
+   * This hook is called by the page level allocators whenever a
+   * complete discontiguous chunk is released.
+   */
+  @Override
+  public int releaseDiscontiguousChunks(Address chunk) {
+    chunkMap.removeChunkFromMap(chunk);
+    return super.releaseDiscontiguousChunks(chunk);
+  }
+
+  /****************************************************************************
+  *
+  * Header manipulation
+  */
+
+ /**
+  * Perform any required post allocation initialization
+  *
+  * @param object the object ref to the storage to be initialized
+  */
+  @Inline
+  public void postAlloc(ObjectReference object, int bytes) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(RCImmixObjectHeader.isNew(object));
+  }
+
+ /**
+  * Perform any required post copy (i.e. in-GC allocation) initialization.
+  * This is relevant (for example) when Squish is used as the mature space in
+  * a copying GC.
+  *
+  * @param object the object ref to the storage to be initialized
+  * @param majorGC Is this copy happening during a major gc?
+  */
+  @Inline
+  public void postCopy(ObjectReference object, int bytes) {
+    RCImmixObjectHeader.writeMarkState(object, bytes > BYTES_IN_LINE);
+    if (!MARK_LINE_AT_SCAN_TIME) RCImmixObjectHeader.testAndMarkLines(object);
+    if (VM.VERIFY_ASSERTIONS) {
+      VM.assertions._assert(RCImmixObjectHeader.isMarked(object));
+    }
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!ForwardingWord.isForwardedOrBeingForwarded(object));
+    if (VM.VERIFY_ASSERTIONS && HeaderByte.NEEDS_UNLOGGED_BIT) VM.assertions._assert(HeaderByte.isUnlogged(object));
+  }
+
+  /****************************************************************************
+   *
+   * Object tracing
+   */
+
+  @Inline
+  public ObjectReference defragTraceObject(TransitiveClosure trace, ObjectReference object) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(rCImmixDefrag.determined(true));
+    traceObjectWithoutMoving(trace, object);
+    return object;
+  }
+
+  @Inline
+  public ObjectReference defragTraceObject(TransitiveClosure trace, ObjectReference object, int allocator) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(rCImmixDefrag.determined(true));
+    if (isDefragSource(object)) {
+      ObjectReference rtn = traceObjectWithOpportunisticCopy(trace, object, allocator);
+      if (VM.VERIFY_ASSERTIONS) {
+        VM.assertions._assert(!rtn.isNull());
+        VM.assertions._assert(rCImmixDefrag.spaceExhausted() || !isDefragSource(rtn) || (RCImmixObjectHeader.isPinnedObject(rtn)));
+      }
+      return rtn;
+    } else {
+      traceObjectAndLineWithoutMoving(trace, object);
+      return object;
+    }
+  }
+
+  /**
+   * Trace a reference to an object in the context of a non-moving collection.  This
+   * call is optimized for the simpler non-moving case.
+   *
+   * @param trace The trace performing the transitive closure
+   * @param object The object to be traced.
+   * @return The object (there is no object forwarding in this
+   * trace method, so we always return the same object: this could be a
+   * void method but for compliance to a more general interface).
+   */
+  @Inline
+  public ObjectReference fastTraceObjectAndLine(TransitiveClosure trace, ObjectReference object) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(rCImmixDefrag.determined(false));
+    traceObjectAndLineWithoutMoving(trace, object);
+    return object;
+  }
+
+  @Inline
+  public ObjectReference fastTraceObject(TransitiveClosure trace, ObjectReference object) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(rCImmixDefrag.determined(false));
+    traceObjectWithoutMoving(trace, object);
+    return object;
+  }
+
+  /**
+   * Trace a reference to an object.  This interface is not supported by immix, since
+   * we require the allocator to be identified except for the special case of the fast
+   * trace.
+   *
+   * @param trace The trace performing the transitive closure
+   * @param object The object to be traced.
+   * @return null and fail.
+   */
+  @Override
+  public ObjectReference traceObject(TransitiveClosure trace, ObjectReference object) {
+    VM.assertions.fail("unsupported interface");
+    return null;
+  }
+
+  /**
+   * Trace a reference to an object in the context of a non-moving collection.  This
+   * call is optimized for the simpler non-moving case.
+   *
+   * @param trace The trace performing the transitive closure
+   * @param object The object to be traced.
+   */
+  @Inline
+  private void traceObjectAndLineWithoutMoving(TransitiveClosure trace, ObjectReference object) {
+    if (RCImmixObjectHeader.testAndMark(object)) {
+      if (!MARK_LINE_AT_SCAN_TIME) RCImmixObjectHeader.testAndMarkLines(object);
+      trace.processNode(object);
+      RCImmixObjectHeader.initRC(object);
+    } else RCImmixObjectHeader.incRC(object);
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!ForwardingWord.isForwardedOrBeingForwarded(object));
+    if (VM.VERIFY_ASSERTIONS  && HeaderByte.NEEDS_UNLOGGED_BIT) VM.assertions._assert(HeaderByte.isUnlogged(object));
+  }
+
+  @Inline
+  private void traceObjectWithoutMoving(TransitiveClosure trace, ObjectReference object) {
+    if (RCImmixObjectHeader.testAndMark(object)) {
+      trace.processNode(object);
+      RCImmixObjectHeader.initRC(object);
+    } else RCImmixObjectHeader.incRC(object);
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!ForwardingWord.isForwardedOrBeingForwarded(object));
+    if (VM.VERIFY_ASSERTIONS  && HeaderByte.NEEDS_UNLOGGED_BIT) VM.assertions._assert(HeaderByte.isUnlogged(object));
+  }
+
+  /**
+   * Trace a reference to an object, forwarding the object if appropriate
+   * If the object is not already marked, mark the object and enqueue it
+   * for subsequent processing.
+   *
+   * @param trace The trace performing the transitive closure
+   * @param object The object to be traced.
+   * @param allocator The allocator to which any copying should be directed
+   * @return Either the object or a forwarded object, if it was forwarded.
+   */
+  @Inline
+  private ObjectReference traceObjectWithOpportunisticCopy(TransitiveClosure trace, ObjectReference object, int allocator) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert((rCImmixDefrag.determined(true) && isDefragSource(object)));
+    // Race to be the (potential) forwarder
+    Word priorStatusWord = ForwardingWord.attemptToForward(object);
+    //Word priorHeaderWord = object.toAddress().loadWord(ObjectHeader.RC_HEADER_OFFSET);
+    if (ForwardingWord.stateIsForwardedOrBeingForwarded(priorStatusWord)) {
+      // We lost the race; the object is either forwarded or being forwarded by another thread.
+      // Note that the concurrent attempt to forward the object may fail, so the object may remain in-place
+      ObjectReference rtn = ForwardingWord.spinAndGetForwardedObject(object, priorStatusWord);
+      if (VM.VERIFY_ASSERTIONS && rtn == object) VM.assertions._assert(RCImmixObjectHeader.isMarked(object) || rCImmixDefrag.spaceExhausted() || RCImmixObjectHeader.isPinnedObject(object));
+      if (VM.VERIFY_ASSERTIONS && rtn != object) VM.assertions._assert(!isDefragSource(rtn));
+      RCImmixObjectHeader.incRC(rtn);
+      return rtn;
+    } else {
+      byte priorState = (byte) (priorStatusWord.toInt() & 0xFF);
+      // the object is unforwarded, either because this is the first thread to reach it, or because the object can't be forwarded
+      if (RCImmixObjectHeader.isMarked(priorState)) {
+        // the object has not been forwarded, but has the correct mark state; unlock and return unmoved object
+        // Note that in a sticky mark bits collector, the mark state does not change at each GC, so correct mark state does not imply another thread got there first
+        if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(rCImmixDefrag.spaceExhausted() || RCImmixObjectHeader.isPinnedObject(object));
+        RCImmixObjectHeader.returnToPriorState(object, priorState); // return to uncontested state
+        RCImmixObjectHeader.incRC(object);
+        return object;
+      } else {
+        if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!RCImmixObjectHeader.isMarked(object));
+        // we are the first to reach the object; either mark in place or forward it
+        ObjectReference newObject;
+        if (RCImmixObjectHeader.isPinnedObject(object) ||  rCImmixDefrag.spaceExhausted()) {
+          // mark in place
+          RCImmixObjectHeader.setMarkStateAndUnlock(object, priorState);
+          newObject = object;
+        } else {
+          // forward
+          if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!RCImmixObjectHeader.isPinnedObject(object));
+          newObject = ForwardingWord.forwardObject(object, allocator);
+        }
+        if (VM.VERIFY_ASSERTIONS && Options.verbose.getValue() >= 9) {
+          Log.write("C["); Log.write(object); Log.write("/");
+          Log.write(getName()); Log.write("] -> ");
+          Log.write(newObject); Log.write("/");
+          Log.write(Space.getSpaceForObject(newObject).getName());
+          Log.writeln("]");
+        }
+        if (!MARK_LINE_AT_SCAN_TIME) RCImmixObjectHeader.testAndMarkLines(newObject);
+        trace.processNode(newObject);
+        RCImmixObjectHeader.initRC(newObject);
+        if (VM.VERIFY_ASSERTIONS) {
+          if (!((getSpaceForObject(newObject) != this) ||
+                (newObject == object) ||
+                (rCImmixDefrag.inDefrag() && willNotMoveThisGC(newObject))
+               )) {
+            Log.write("   object: "); Log.writeln(object);
+            Log.write("newObject: "); Log.writeln(newObject);
+            Log.write("    space: "); Log.writeln(getName());
+            Space otherSpace = getSpaceForObject(newObject);
+            Log.write(" space(o): "); Log.writeln(otherSpace == null ? "<NULL>" : otherSpace.getName());
+            VM.assertions._assert(false);
+          }
+        }
+        return newObject;
+      }
+    }
+  }
+
+  public int getNextUnavailableLine(Address baseLineAvailAddress, int line) {
+    return RCImmixLine.getNextUnavailable(baseLineAvailAddress, line);
+  }
+
+  public int getNextAvailableLine(Address baseLineAvailAddress, int line) {
+    return RCImmixLine.getNextAvailable(baseLineAvailAddress, line);
+  }
+
+  /****************************************************************************
+  *
+  * Establish available lines
+  */
+
+  /**
+   * Establish the number of recyclable lines lines available for allocation
+   * during defragmentation, populating the spillAvailHistogram, which buckets
+   * available lines according to the number of holes on the block on which
+   * the available lines reside.
+   *
+   * @param spillAvailHistogram A histogram of availability to be populated
+   * @return The number of available recyclable lines
+   */
+  int getAvailableLines(int[] spillAvailHistogram) {
+    int availableLines;
+    if (allocBlockCursor.isZero() || exhaustedReusableSpace) {
+      availableLines = 0;
+    } else {
+      if (allocBlockCursor.EQ(allocBlockSentinel)) {
+        if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!exhaustedReusableSpace);
+        allocBlockCursor = chunkMap.getHeadChunk();
+        allocBlockSentinel = allocBlockCursor;
+      }
+      availableLines = getUsableLinesInRegion(allocBlockCursor, allocBlockSentinel, spillAvailHistogram);
+    }
+    return availableLines;
+  }
+
+  /**
+   * Return the number of lines usable for allocation during defragmentation in the
+   * address range specified by start and end.  Populate a histogram to indicate where
+   * the usable lines reside as a function of block hole count.
+   *
+   * @param start  The start of the region to be checked for availability
+   * @param end The end of the region to be checked for availability
+   * @param spillAvailHistogram The histogram which will be populated
+   * @return The number of usable lines
+   */
+  private int getUsableLinesInRegion(Address start, Address end, int[] spillAvailHistogram) {
+    int usableLines = 0;
+    Address blockCursor = RCImmixChunk.isAligned(start) ? start.plus(RCImmixChunk.FIRST_USABLE_BLOCK_INDEX<<LOG_BYTES_IN_BLOCK) : start;
+    Address blockStateCursor = RCImmixBlock.getBlockMarkStateAddress(blockCursor);
+    Address chunkCursor = RCImmixChunk.align(blockCursor);
+    if (RCImmixChunk.getByteOffset(end) < RCImmixChunk.FIRST_USABLE_BLOCK_INDEX<<LOG_BYTES_IN_BLOCK)
+      end = RCImmixChunk.align(end).plus(RCImmixChunk.FIRST_USABLE_BLOCK_INDEX<<LOG_BYTES_IN_BLOCK);
+
+    for (int i = 0; i <= MAX_CONSV_SPILL_COUNT; i++) spillAvailHistogram[i] = 0;
+
+    Address highwater = RCImmixChunk.getHighWater(chunkCursor);
+    do {
+      short markState = blockStateCursor.loadShort();
+      if (markState != 0 && markState <= reusableMarkStateThreshold) {
+        int usable = LINES_IN_BLOCK - markState;
+        short bucket = RCImmixBlock.getConservativeSpillCount(blockCursor);
+        if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(bucket >= 0 && bucket <= MAX_CONSV_SPILL_COUNT);
+        spillAvailHistogram[bucket] += usable;
+        usableLines += usable;
+      }
+      blockCursor = blockCursor.plus(BYTES_IN_BLOCK);
+      if (blockCursor.GT(highwater)) {
+        chunkCursor = chunkMap.nextChunk(chunkCursor);
+        if (chunkCursor.isZero()) break;
+        blockCursor = chunkCursor.plus(RCImmixChunk.FIRST_USABLE_BLOCK_INDEX<<LOG_BYTES_IN_BLOCK);
+        blockStateCursor = RCImmixBlock.getBlockMarkStateAddress(blockCursor);
+        highwater = RCImmixChunk.getHighWater(chunkCursor);
+      } else
+        blockStateCursor = blockStateCursor.plus(RCImmixBlock.BYTES_IN_BLOCK_STATE_ENTRY);
+    } while (blockCursor.NE(end));
+
+    return usableLines;
+  }
+
+  /****************************************************************************
+   *
+   * Object state
+   */
+
+  /**
+   * Generic test of the liveness of an object
+   *
+   * @param object The object in question
+   * @return {@code true} if this object is known to be live (i.e. it is marked)
+   */
+  @Override
+  @Inline
+  public boolean isLive(ObjectReference object) {
+    if (rCImmixDefrag.inDefrag() && isDefragSource(object))
+      return ForwardingWord.isForwardedOrBeingForwarded(object) || RCImmixObjectHeader.isMarked(object);
+    else
+      return RCImmixObjectHeader.isMarked(object);
+  }
+
+  /**
+   * Test the liveness of an object during defragmentation
+   *
+   * @param object The object in question
+   * @return {@code true} if this object is known to be live (i.e. it is marked)
+   */
+  @Inline
+  public boolean fastIsLive(ObjectReference object) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!rCImmixDefrag.inDefrag());
+    return RCImmixObjectHeader.isMarked(object);
+  }
+
+  @Inline
+  public boolean willNotMoveThisGC(ObjectReference object) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(getSpaceForObject(object) == this && rCImmixDefrag.inDefrag());
+    return RCImmixObjectHeader.isPinnedObject(object) || willNotMoveThisGC(VM.objectModel.refToAddress(object));
+  }
+
+  @Inline
+  private boolean isDefragSource(ObjectReference object) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(getSpaceForObject(object) == this);
+    return isDefragSource(VM.objectModel.refToAddress(object));
+  }
+
+  @Inline
+  public boolean willNotMoveThisGC(Address address) {
+    return !rCImmixDefrag.inDefrag() || rCImmixDefrag.spaceExhausted() || !isDefragSource(address);
+  }
+
+  @Inline
+  public boolean isDefragSource(Address address) {
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(getSpaceForObject(address.toObjectReference()) == this);
+    return RCImmixBlock.isDefragSource(address);
+  }
+
+
+  /****************************************************************************
+   *
+   * Locks
+   */
+
+  /**
+   * Acquire the appropriate lock depending on whether the context is
+   * GC or mutator.
+   */
+  private void lock() {
+    if (inCollection)
+      gcLock.acquire();
+    else
+      mutatorLock.acquire();
+  }
+
+   /**
+    * Release the appropriate lock depending on whether the context is
+    * GC or mutator.
+    */
+  private void unlock() {
+    if (inCollection)
+      gcLock.release();
+    else
+       mutatorLock.release();
+  }
+
+
+ /****************************************************************************
+  *
+  * Misc
+  */
+
+  /**
+   *
+   */
+  public static boolean isRecycleAllocChunkAligned(Address ptr) {
+    return ptr.toWord().and(RECYCLE_ALLOC_CHUNK_MASK).EQ(Word.zero());
+  }
+
+  @Inline
+  public void postCopyYoungObject(ObjectReference object, int bytes) {
+    RCImmixObjectHeader.writeStateYoungObject(object, bytes > BYTES_IN_LINE);
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!ForwardingWord.isForwardedOrBeingForwarded(object));
+    if (VM.VERIFY_ASSERTIONS && HeaderByte.NEEDS_UNLOGGED_BIT) VM.assertions._assert(HeaderByte.isUnlogged(object));
+  }
+
+  RCImmixChunkList getChunkMap() { return chunkMap; }
+  RCImmixDefrag getDefrag() { return rCImmixDefrag; }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/utility/ForwardingWord.java
--- a/MMTk/src/org/mmtk/utility/ForwardingWord.java	Wed May 20 12:33:21 2015 +0200
+++ b/MMTk/src/org/mmtk/utility/ForwardingWord.java	Fri Jun 05 16:07:58 2015 +0600
@@ -45,14 +45,14 @@
    */
   private static final byte FORWARDING_NOT_TRIGGERED_YET = 0; // ...00
   /** If this bit is set, then forwarding of this object is incomplete */
-  private static final byte BEING_FORWARDED = 2; // ...10
+  private static final byte BEING_FORWARDED = 3; // ...10
   /** If this bit is set, then forwarding of this object has commenced */
-  private static final byte FORWARDED =       3; // ...11
+  private static final byte FORWARDED =       2; // ...11
   /** This mask is used to reveal which state this object is in with respect to forwarding */
   public static final byte FORWARDING_MASK =  3; // ...11
 
   public static final int FORWARDING_BITS = 2;
-
+  public static final byte CLEAR_FORWARDING = 1;
 
   /**
    * Either return the forwarding pointer if the object is already
@@ -127,7 +127,9 @@
    */
   @Inline
   public static boolean isForwardedOrBeingForwarded(ObjectReference object) {
-    return (VM.objectModel.readAvailableByte(object) & FORWARDING_MASK) != 0;
+    //return (VM.objectModel.readAvailableByte(object) & FORWARDING_MASK) != 0;
+    byte value = (byte) (VM.objectModel.readAvailableByte(object) & FORWARDING_MASK);
+    return (value == BEING_FORWARDED)  || (value == FORWARDED);
   }
 
   /**
@@ -138,7 +140,9 @@
    */
   @Inline
   public static boolean stateIsForwardedOrBeingForwarded(Word header) {
-    return (header.toInt() & FORWARDING_MASK) != 0;
+    //return (header.toInt() & FORWARDING_MASK) != 0;
+    byte value = (byte) (header.toInt() & FORWARDING_MASK);
+    return (value == BEING_FORWARDED)  || (value == FORWARDED);
   }
 
   /**
diff -r ba76b741d3fe MMTk/src/org/mmtk/utility/HeaderByte.java
--- a/MMTk/src/org/mmtk/utility/HeaderByte.java	Wed May 20 12:33:21 2015 +0200
+++ b/MMTk/src/org/mmtk/utility/HeaderByte.java	Fri Jun 05 16:07:58 2015 +0600
@@ -14,7 +14,6 @@
 
 import org.mmtk.vm.VM;
 import org.vmmagic.pragma.Uninterruptible;
-import org.vmmagic.unboxed.Address;
 import org.vmmagic.unboxed.ObjectReference;
 
 /**
@@ -36,25 +35,6 @@
   public static final int USED_GLOBAL_BITS = TOTAL_BITS - UNLOGGED_BIT_NUMBER;
 
 
-  /**
-   * Perform any required initialization of the GC portion of the header.
-   * Called for objects created at boot time.
-   *
-   * @param object the Address representing the storage to be initialized
-   * @param typeRef the type reference for the instance being created
-   * @param size the number of bytes allocated by the GC system for
-   * this object.
-   * @return The new value of the status word
-   */
-  public static byte setBuildTimeGCByte(Address object, ObjectReference typeRef, int size) {
-    byte status = 0;
-
-    if (NEEDS_UNLOGGED_BIT)
-      status |= UNLOGGED_BIT;
-    return status;
-  }
-
-
   public static void markAsUnlogged(ObjectReference object) {
     byte value = VM.objectModel.readAvailableByte(object);
     VM.objectModel.writeAvailableByte(object, (byte) (value | UNLOGGED_BIT));
diff -r ba76b741d3fe MMTk/src/org/mmtk/utility/alloc/ImmixAllocator.java
--- a/MMTk/src/org/mmtk/utility/alloc/ImmixAllocator.java	Wed May 20 12:33:21 2015 +0200
+++ b/MMTk/src/org/mmtk/utility/alloc/ImmixAllocator.java	Fri Jun 05 16:07:58 2015 +0600
@@ -178,8 +178,13 @@
    */
   @Override
   protected final Address allocSlowOnce(int bytes, int align, int offset) {
-    Address ptr = space.getSpace(hot, copy, lineUseCount);
-
+    //Address ptr = space.getSpace(hot, copy, lineUseCount);
+    Address ptr = Address.zero();
+    while (true) {
+      ptr = space.getSpace(hot, copy, lineUseCount);
+      if (!ptr.isZero()) break;
+    }
+    
     if (ptr.isZero()) {
       lineUseCount = 0;
       return ptr; // failed allocation --- we will need to GC
diff -r ba76b741d3fe MMTk/src/org/mmtk/utility/alloc/RCImmixAllocator.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/utility/alloc/RCImmixAllocator.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,333 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+
+package org.mmtk.utility.alloc;
+
+import org.mmtk.policy.Space;
+import org.mmtk.policy.rcimmix.RCImmixBlock;
+import org.mmtk.policy.rcimmix.RCImmixChunk;
+import org.mmtk.policy.rcimmix.RCImmixSpace;
+import org.mmtk.policy.rcimmix.RCImmixLine;
+
+import static org.mmtk.policy.rcimmix.RCImmixConstants.*;
+
+import org.mmtk.utility.Log;
+import org.mmtk.utility.options.Options;
+import org.mmtk.vm.VM;
+import org.vmmagic.unboxed.*;
+import org.vmmagic.pragma.*;
+
+/**
+ *
+ */
+@Uninterruptible
+public class RCImmixAllocator extends Allocator {
+
+  /****************************************************************************
+   *
+   * Instance variables
+   */
+  protected final RCImmixSpace space;    /* space this allocator is associated with */
+  private final boolean hot;
+  private final boolean copy;
+
+  private Address cursor;               /* bump pointer */
+  private Address limit;                /* limit for bump pointer */
+  private Address largeCursor;          /* bump pointer for large objects */
+  private Address largeLimit;           /* limit for bump pointer for large objects */
+  private boolean requestForLarge;      /* is the current request for large or small? */
+  private boolean straddle;             /* did the last allocation straddle a line? */
+  private int lineUseCount;             /* approximation to bytes allocated (measured at 99% accurate)  07/10/30 */
+  private Address recyclableBlock;
+  private int line;
+  private boolean recyclableExhausted;
+
+  /**
+   * Constructor.
+   *
+   * @param space The space to bump point into.
+   * @param hot TODO
+   * @param copy TODO
+   */
+  public RCImmixAllocator(RCImmixSpace space, boolean hot, boolean copy) {
+    this.space = space;
+    this.hot = hot;
+    this.copy = copy;
+    reset();
+  }
+
+  /**
+   * Reset the allocator. Note that this does not reset the space.
+   */
+  public void reset() {
+    cursor = Address.zero();
+    limit = Address.zero();
+    largeCursor = Address.zero();
+    largeLimit = Address.zero();
+    recyclableBlock = Address.zero();
+    requestForLarge = false;
+    recyclableExhausted = false;
+    line = LINES_IN_BLOCK;
+    lineUseCount = 0;
+  }
+
+  /*****************************************************************************
+   *
+   * Public interface
+   */
+
+  /**
+   * Allocate space for a new object.  This is frequently executed code and
+   * the coding is deliberaetly sensitive to the optimizing compiler.
+   * After changing this, always check the IR/MC that is generated.
+   *
+   * @param bytes The number of bytes allocated
+   * @param align The requested alignment
+   * @param offset The offset from the alignment
+   * @return The address of the first byte of the allocated region
+   */
+  @Inline
+  public final Address alloc(int bytes, int align, int offset) {
+    /* establish how much we need */
+    Address start = alignAllocationNoFill(cursor, align, offset);
+    Address end = start.plus(bytes);
+    /* check whether we've exceeded the limit */
+    if (end.GT(limit)) {
+      if (bytes > BYTES_IN_LINE) {
+        return overflowAlloc(bytes, align, offset);
+      } else {
+        return allocSlowHot(bytes, align, offset);
+      }
+    }
+    /* sufficient memory is available, so we can finish performing the allocation */
+    fillAlignmentGap(cursor, start);
+    cursor = end;
+
+    return start;
+  }
+
+  /**
+   * Allocate space for a new object.  This is frequently executed code and
+   * the coding is deliberaetly sensitive to the optimizing compiler.
+   * After changing this, always check the IR/MC that is generated.
+   *
+   * @param bytes The number of bytes allocated
+   * @param align The requested alignment
+   * @param offset The offset from the alignment
+   * @return The address of the first byte of the allocated region
+   */
+  public final Address overflowAlloc(int bytes, int align, int offset) {
+    /* establish how much we need */
+    Address start = alignAllocationNoFill(largeCursor, align, offset);
+    Address end = start.plus(bytes);
+
+    /* check whether we've exceeded the limit */
+    if (end.GT(largeLimit)) {
+      requestForLarge = true;
+      Address rtn =  allocSlowInline(bytes, align, offset);
+      requestForLarge = false;
+      return rtn;
+    }
+
+    /* sufficient memory is available, so we can finish performing the allocation */
+    fillAlignmentGap(largeCursor, start);
+    largeCursor = end;
+
+    return start;
+  }
+
+  @Inline
+  public final boolean getLastAllocLineStraddle() {
+    return straddle;
+  }
+
+  /**
+   * External allocation slow path (called by superclass when slow path is
+   * actually taken.  This is necessary (rather than a direct call
+   * from the fast path) because of the possibility of a thread switch
+   * and corresponding re-association of bump pointers to kernel
+   * threads.
+   *
+   * @param bytes The number of bytes allocated
+   * @param align The requested alignment
+   * @param offset The offset from the alignment
+   * @return The address of the first byte of the allocated region or
+   * zero on failure
+   */
+  protected final Address allocSlowOnce(int bytes, int align, int offset) {
+    //Address ptr = space.getSpace(hot, copy, lineUseCount);
+    Address ptr = Address.zero();
+    while (true) {
+      ptr = space.getSpace(hot, copy, lineUseCount);
+      if (!ptr.isZero()) break;
+    }
+
+    if (ptr.isZero()) {
+      lineUseCount = 0;
+      return ptr; // failed allocation --- we will need to GC
+    }
+
+    /* we have been given a clean block */
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(RCImmixBlock.isAligned(ptr));
+    lineUseCount = LINES_IN_BLOCK;
+
+    zeroLinesOfBlock(ptr);
+    if (requestForLarge) {
+      largeCursor = ptr;
+      largeLimit = ptr.plus(BYTES_IN_BLOCK);
+    } else {
+      cursor = ptr;
+      limit = ptr.plus(BYTES_IN_BLOCK);
+    }
+
+    return alloc(bytes, align, offset);
+  }
+
+  /****************************************************************************
+   *
+   * Bump allocation
+   */
+
+  /**
+   * Internal allocation slow path.  This is called whenever the bump
+   * pointer reaches the internal limit.  The code is forced out of
+   * line.  If required we perform an external slow path take, which
+   * we inline into this method since this is already out of line.
+   *
+   * @param bytes The number of bytes allocated
+   * @param align The requested alignment
+   * @param offset The offset from the alignment
+   * @return The address of the first byte of the allocated region
+   */
+  @NoInline
+  private Address allocSlowHot(int bytes, int align, int offset) {
+    if (acquireRecyclableLines(bytes, align, offset)) {
+      return alloc(bytes, align, offset);
+    } else {
+      return allocSlowInline(bytes, align, offset);
+    }
+  }
+
+  private boolean acquireRecyclableLines(int bytes, int align, int offset) {
+    while (line < LINES_IN_BLOCK || acquireRecyclableBlock()) {
+      line = space.getNextAvailableLine(recyclableBlock, line);
+      if (line < LINES_IN_BLOCK) {
+        int endLine = space.getNextUnavailableLine(recyclableBlock, line);
+        cursor = recyclableBlock.plus(Extent.fromIntSignExtend(line<<LOG_BYTES_IN_LINE));
+        limit = recyclableBlock.plus(Extent.fromIntSignExtend(endLine<<LOG_BYTES_IN_LINE));
+        if (SANITY_CHECK_LINE_MARKS) {
+          Address tmp = cursor;
+          while (tmp.LT(limit)) {
+            if (tmp.loadByte() != (byte) 0) {
+              Log.write("cursor: "); Log.writeln(cursor);
+              Log.write(" limit: "); Log.writeln(limit);
+              Log.write("current: "); Log.write(tmp);
+              Log.write("  value: "); Log.write(tmp.loadByte());
+              Log.write("   line: "); Log.write(line);
+              Log.write("endline: "); Log.write(endLine);
+              Log.write("  chunk: "); Log.write(RCImmixChunk.align(cursor));
+              Log.write("     hw: "); Log.write(RCImmixChunk.getHighWater(RCImmixChunk.align(cursor)));
+              Log.writeln(" values: ");
+              Address tmp2 = cursor;
+              while(tmp2.LT(limit)) { Log.write(tmp2.loadByte()); Log.write(" ");}
+              Log.writeln();
+            }
+            VM.assertions._assert(tmp.loadByte() == (byte) 0);
+            tmp = tmp.plus(1);
+          }
+        }
+        if (VM.VERIFY_ASSERTIONS && bytes <= BYTES_IN_LINE) {
+          Address start = alignAllocationNoFill(cursor, align, offset);
+          Address end = start.plus(bytes);
+          VM.assertions._assert(end.LE(limit));
+        }
+        VM.memory.zero(false, cursor, limit.diff(cursor).toWord().toExtent());
+        if (VM.VERIFY_ASSERTIONS && Options.verbose.getValue() >= 9) {
+          Log.write("Z["); Log.write(cursor); Log.write("->"); Log.write(limit); Log.writeln("]");
+        }
+
+        line = endLine;
+        if (VM.VERIFY_ASSERTIONS && copy) VM.assertions._assert(!RCImmixBlock.isDefragSource(cursor));
+        return true;
+      }
+    }
+    return false;
+  }
+
+
+  private boolean acquireRecyclableBlock() {
+    boolean rtn;
+    rtn = acquireRecyclableBlockAddressOrder();
+    if (rtn) {
+      line = 0;
+    }
+    return rtn;
+  }
+
+
+  @Inline
+  private boolean acquireRecyclableBlockAddressOrder() {
+    if (recyclableExhausted) {
+      if (VM.VERIFY_ASSERTIONS && Options.verbose.getValue() >= 9) {
+        Log.writeln("[no recyclable available]");
+      }
+      return false;
+    }
+    int markState = 0;
+    boolean usable = false;
+    while (!usable) {
+      Address next = recyclableBlock.plus(BYTES_IN_BLOCK);
+      if (recyclableBlock.isZero() || RCImmixSpace.isRecycleAllocChunkAligned(next)) {
+        recyclableBlock = space.acquireReusableBlocks();
+        if (recyclableBlock.isZero()) {
+          recyclableExhausted = true;
+          if (VM.VERIFY_ASSERTIONS && Options.verbose.getValue() >= 9) {
+            Log.writeln("[recyclable exhausted]");
+          }
+          line = LINES_IN_BLOCK;
+          return false;
+        }
+      } else {
+        recyclableBlock = next;
+      }
+      markState = RCImmixBlock.getBlockMarkState(recyclableBlock);
+      usable = (markState > 0 && markState <= RCImmixSpace.getReusuableMarkStateThreshold(copy));
+      if (copy && RCImmixBlock.isDefragSource(recyclableBlock))
+        usable = false;
+    }
+    if (VM.VERIFY_ASSERTIONS) VM.assertions._assert(!RCImmixBlock.isUnused(recyclableBlock));
+    RCImmixBlock.setBlockAsReused(recyclableBlock);
+
+    lineUseCount += (LINES_IN_BLOCK-markState);
+    return true; // found something good
+  }
+
+  @Inline
+  private void zeroLinesOfBlock(Address block) {
+    Address start = RCImmixLine.getRCAddress(RCImmixLine.align(block));
+    VM.memory.zero(false, start, Extent.fromIntZeroExtend(LINES_IN_BLOCK << RCImmixLine.LOG_BYTES_IN_LINE_RC_ENTRY));
+  }
+
+
+  /** @return the space associated with this squish allocator */
+  @Override
+  public final Space getSpace() { return space; }
+
+  /**
+   * Print out the status of the allocator (for debugging)
+   */
+  public final void show() {
+    Log.write("cursor = "); Log.write(cursor);
+    Log.write(" limit = "); Log.writeln(limit);
+  }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/utility/options/CycleTriggerFraction.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/utility/options/CycleTriggerFraction.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,35 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.utility.options;
+
+/**
+ * Should a major GC be performed when a system GC is triggered?
+ */
+public final class CycleTriggerFraction extends org.vmutil.options.FloatOption {
+  /**
+   * Create the option.
+   */
+  public CycleTriggerFraction() {
+    super(Options.set, "Cycle Trigger Fraction",
+          "Should a major GC be performed when a system GC is triggered?",
+          0.01f);
+  }
+
+  /**
+   * Ensure the value is valid.
+   */
+  @Override
+  protected void validate() {
+    failIf((this.value < 0 || this.value > 1.0), "Ratio must be a float between 0 and 1");
+  }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/utility/options/DefragTriggerFraction.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/utility/options/DefragTriggerFraction.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,35 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.utility.options;
+
+/**
+ * Should a major GC be performed when a system GC is triggered?
+ */
+public final class DefragTriggerFraction extends org.vmutil.options.FloatOption {
+  /**
+   * Create the option.
+   */
+  public DefragTriggerFraction() {
+    super(Options.set, "Defrag Trigger Fraction",
+          "Should a major GC be performed when a system GC is triggered?",
+          0.01f);
+  }
+
+  /**
+   * Ensure the value is valid.
+   */
+  @Override
+  protected void validate() {
+    failIf((this.value < 0 || this.value > 1.0), "Ratio must be a float between 0 and 1");
+  }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/utility/options/Options.java
--- a/MMTk/src/org/mmtk/utility/options/Options.java	Wed May 20 12:33:21 2015 +0200
+++ b/MMTk/src/org/mmtk/utility/options/Options.java	Fri Jun 05 16:07:58 2015 +0600
@@ -67,4 +67,7 @@
   public static Verbose verbose;
   public static VerboseTiming verboseTiming;
   public static XmlStats xmlStats;
+  public static CycleTriggerFraction cycleTriggerFraction;
+  public static DefragTriggerFraction defragTriggerFraction;
+  public static SurvivorCopyMultiplier survivorCopyMultiplier;
 }
diff -r ba76b741d3fe MMTk/src/org/mmtk/utility/options/SurvivorCopyMultiplier.java
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/MMTk/src/org/mmtk/utility/options/SurvivorCopyMultiplier.java	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,34 @@
+/*
+ *  This file is part of the Jikes RVM project (http://jikesrvm.org).
+ *
+ *  This file is licensed to You under the Eclipse Public License (EPL);
+ *  You may not use this file except in compliance with the License. You
+ *  may obtain a copy of the License at
+ *
+ *      http://www.opensource.org/licenses/eclipse-1.0.php
+ *
+ *  See the COPYRIGHT.txt file distributed with this work for information
+ *  regarding copyright ownership.
+ */
+package org.mmtk.utility.options;
+
+import static org.mmtk.policy.rcimmix.RCImmixConstants.DEFAULT_SURVIVOR_COPY_MULTIPLIER;
+
+public class SurvivorCopyMultiplier extends org.vmutil.options.FloatOption {
+  /**
+   * Create the option.
+   */
+  public SurvivorCopyMultiplier() {
+    super(Options.set, "Survivor Copy Multiplier",
+          "Allow the copy this fraction of the heap as headroom during survivor copy.",
+          DEFAULT_SURVIVOR_COPY_MULTIPLIER);
+  }
+
+  /**
+   * Ensure the value is valid.
+   */
+  @Override
+  protected void validate() {
+    failIf((this.value < 0 || this.value > 5.0), "Ratio must be a float between 0 and 1");
+  }
+}
diff -r ba76b741d3fe MMTk/src/org/mmtk/vm/Config.java
--- a/MMTk/src/org/mmtk/vm/Config.java	Wed May 20 12:33:21 2015 +0200
+++ b/MMTk/src/org/mmtk/vm/Config.java	Fri Jun 05 16:07:58 2015 +0600
@@ -22,15 +22,20 @@
   /** Mark bit in the header or on the side ? */
   public final boolean HEADER_MARK_BITS;
 
+  /** Pinning bit? */
+  public final boolean PINNING_BIT;
+
   Config(BuildTimeConfig config) {
     ACTIVE_PLAN            = config.getPlanName();
     HEADER_MARK_BITS        = config.getBooleanProperty("mmtk.headerMarkBit",true);
+    PINNING_BIT        = config.getBooleanProperty("mmtk.pinningBit",false);
   }
 
   public void printConfig() {
     Log.writeln("================ MMTk Configuration ================");
     Log.write("plan = "); Log.writeln(ACTIVE_PLAN);
     Log.write("HEADER_MARK_BITS = ");  Log.writeln(HEADER_MARK_BITS);
+    Log.write("PINNING_BIT = ");  Log.writeln(PINNING_BIT);
     Log.writeln("====================================================");
   }
 
@@ -38,6 +43,7 @@
     Log.writeln("<config>");
     Xml.configItem("plan",ACTIVE_PLAN);
     Xml.configItem("header-mark-bit",HEADER_MARK_BITS);
+    Xml.configItem("pinning-bit",PINNING_BIT);
     Log.writeln("</config>");
   }
 }
diff -r ba76b741d3fe build/configs/BaseBaseRCImmix.properties
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/build/configs/BaseBaseRCImmix.properties	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,13 @@
+#
+#  This file is part of the Jikes RVM project (http://jikesrvm.org).
+#
+#  This file is licensed to You under the Eclipse Public License (EPL);
+#  You may not use this file except in compliance with the License. You
+#  may obtain a copy of the License at
+#
+#      http://www.opensource.org/licenses/eclipse-1.0.php
+#
+#  See the COPYRIGHT.txt file distributed with this work for information
+#  regarding copyright ownership.
+#
+config.mmtk.plan=org.mmtk.plan.rcimmix.RCImmix
diff -r ba76b741d3fe build/configs/FastAdaptiveRCImmix.properties
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/build/configs/FastAdaptiveRCImmix.properties	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,19 @@
+#
+#  This file is part of the Jikes RVM project (http://jikesrvm.org).
+#
+#  This file is licensed to You under the Eclipse Public License (EPL);
+#  You may not use this file except in compliance with the License. You
+#  may obtain a copy of the License at
+#
+#      http://www.opensource.org/licenses/eclipse-1.0.php
+#
+#  See the COPYRIGHT.txt file distributed with this work for information
+#  regarding copyright ownership.
+#
+config.mmtk.plan=org.mmtk.plan.rcimmix.RCImmix
+config.include.aos=true
+config.assertions=none
+config.default-heapsize.initial=50
+config.runtime.compiler=opt
+config.bootimage.compiler=opt
+config.bootimage.compiler.args=-X:bc:O2
diff -r ba76b741d3fe build/configs/FullAdaptiveRCImmix.properties
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/build/configs/FullAdaptiveRCImmix.properties	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,18 @@
+#
+#  This file is part of the Jikes RVM project (http://jikesrvm.org).
+#
+#  This file is licensed to You under the Eclipse Public License (EPL);
+#  You may not use this file except in compliance with the License. You
+#  may obtain a copy of the License at
+#
+#      http://www.opensource.org/licenses/eclipse-1.0.php
+#
+#  See the COPYRIGHT.txt file distributed with this work for information
+#  regarding copyright ownership.
+#
+config.mmtk.plan=org.mmtk.plan.rcimmix.RCImmix
+config.include.aos=true
+config.default-heapsize.initial=50
+config.runtime.compiler=opt
+config.bootimage.compiler=opt
+config.bootimage.compiler.args=-X:bc:O2
diff -r ba76b741d3fe build/configs/rcimmix.properties
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/build/configs/rcimmix.properties	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,19 @@
+#
+#  This file is part of the Jikes RVM project (http://jikesrvm.org).
+#
+#  This file is licensed to You under the Eclipse Public License (EPL);
+#  You may not use this file except in compliance with the License. You
+#  may obtain a copy of the License at
+#
+#      http://www.opensource.org/licenses/eclipse-1.0.php
+#
+#  See the COPYRIGHT.txt file distributed with this work for information
+#  regarding copyright ownership.
+#
+config.mmtk.plan=org.mmtk.plan.rcimmix.RCImmix
+config.include.aos=true
+config.assertions=none
+config.default-heapsize.initial=50
+config.runtime.compiler=opt
+config.bootimage.compiler=opt
+config.bootimage.compiler.args=-X:bc:O2
diff -r ba76b741d3fe build/mmtk/pinning.properties
--- /dev/null	Thu Jan 01 00:00:00 1970 +0000
+++ b/build/mmtk/pinning.properties	Fri Jun 05 16:07:58 2015 +0600
@@ -0,0 +1,14 @@
+#
+#  This file is part of the Jikes RVM project (http://jikesrvm.org).
+#
+#  This file is licensed to You under the Eclipse Public License (EPL);
+#  You may not use this file except in compliance with the License. You
+#  may obtain a copy of the License at
+#
+#      http://www.opensource.org/licenses/eclipse-1.0.php
+#
+#  See the COPYRIGHT.txt file distributed with this work for information
+#  regarding copyright ownership.
+#
+# MMTk properties file to support pinning.  
+mmtk.pinningBit = true
\ No newline at end of file
diff -r ba76b741d3fe rvm/src/org/jikesrvm/mm/mminterface/MemoryManager.java
--- a/rvm/src/org/jikesrvm/mm/mminterface/MemoryManager.java	Wed May 20 12:33:21 2015 +0200
+++ b/rvm/src/org/jikesrvm/mm/mminterface/MemoryManager.java	Fri Jun 05 16:07:58 2015 +0600
@@ -1149,7 +1149,7 @@
   public static void initializeHeader(BootImageInterface bootImage, Address ref, TIB tib, int size,
                                       boolean isScalar) {
     //    int status = JavaHeader.readAvailableBitsWord(bootImage, ref);
-    byte status = org.mmtk.utility.HeaderByte.setBuildTimeGCByte(ref, ObjectReference.fromObject(tib), size);
+    byte status = Selected.Plan.get().setBuildTimeGCByte(ref, ObjectReference.fromObject(tib), size);
     JavaHeader.writeAvailableByte(bootImage, ref, status);
   }
 
